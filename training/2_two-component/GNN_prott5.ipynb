{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4cb3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reproducibility seeds set with SEED=42\n",
      "Using device: cuda\n",
      "CUDA Device Name: Tesla V100-PCIE-32GB\n",
      "ProtT5 embedding dimension set to: 1024\n",
      "Expected rich edge feature dimension set to: 17\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# PyG imports\n",
    "from torch_geometric.nn import GCNConv, GATv2Conv, PNAConv, GINEConv\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool\n",
    "from torch_geometric.data import Data, DataLoader, Batch # Explicitly import Batch\n",
    "from torch_geometric.utils import degree # Keep degree for PNA\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import traceback # For detailed error reporting\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.preprocessing import RobustScaler # Not used directly in this version\n",
    "# import matplotlib.pyplot as plt # Keep if visualizing later\n",
    "import random\n",
    "import os\n",
    "import time # Optional: for timing execution\n",
    "from typing import Optional, Tuple, Dict, List # Type hints for clarity\n",
    "\n",
    "# --- Reproducibility Setup ---\n",
    "SEED = 42 # Or choose a specific seed for this run\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    # Optional: For stricter reproducibility (can slow down training)\n",
    "    # torch.backends.cudnn.deterministic = True\n",
    "    # torch.backends.cudnn.benchmark = False\n",
    "print(f\"Reproducibility seeds set with SEED={SEED}\")\n",
    "\n",
    "# --- Device Configuration ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Device Name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# --- Constants ---\n",
    "# Amino acid definitions (for node features)\n",
    "AMINO_ACIDS = 'ARNDCQEGHILKMFPSTWYV-' # Includes padding char\n",
    "AA_TO_INT = {aa: i for i, aa in enumerate(AMINO_ACIDS)}\n",
    "VALID_AA = 'ARNDCQEGHILKMFPSTWYV'  # Valid amino acids for one-hot encoding\n",
    "\n",
    "# ProtT5 Embedding dimension\n",
    "PROT_T5_DIM = 1024\n",
    "print(f\"ProtT5 embedding dimension set to: {PROT_T5_DIM}\")\n",
    "\n",
    "# Expected edge feature dimension (if using rich features)\n",
    "EXPECTED_EDGE_FEATURE_DIM = 17 # Corrected dimension\n",
    "print(f\"Expected rich edge feature dimension set to: {EXPECTED_EDGE_FEATURE_DIM}\")\n",
    "\n",
    "\n",
    "# Default sequence length and central K position (used in data prep validation)\n",
    "EXPECTED_SEQ_LEN = 33\n",
    "CENTRAL_K_POS_ABS = 16 # 0-based index\n",
    "\n",
    "# --- ProtT5 Data Loading and Alignment Functions ---\n",
    "\n",
    "def load_prot_t5_data(pos_file: str, neg_file: str) -> Tuple[Optional[Dict], Optional[Dict]]:\n",
    "    \"\"\"\n",
    "    Load ProtT5 embeddings from positive and negative sample files.\n",
    "\n",
    "    Args:\n",
    "        pos_file (str): Path to the CSV file with positive sample embeddings.\n",
    "                          Expected format: entry,pos,embedding_vector...\n",
    "        neg_file (str): Path to the CSV file with negative sample embeddings.\n",
    "                          Expected format: entry,pos,embedding_vector...\n",
    "\n",
    "    Returns:\n",
    "        tuple: (pos_dict, neg_dict) where dictionaries map (entry, pos)\n",
    "               tuples to their embedding lists (as floats), or (None, None) on error.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(f\"Loading ProtT5 data...\")\n",
    "    print(f\"  Positive file: {pos_file}\")\n",
    "    print(f\"  Negative file: {neg_file}\")\n",
    "\n",
    "    # Helper function to parse one embedding file\n",
    "    def _parse_emb_file(filepath):\n",
    "        data_list = []\n",
    "        loaded_count = 0\n",
    "        skipped_count = 0\n",
    "        try:\n",
    "            with open(filepath, 'r') as f:\n",
    "                for i, line in enumerate(f):\n",
    "                    try:\n",
    "                        parts = line.strip().split(',')\n",
    "                        if len(parts) < 3: skipped_count += 1; continue\n",
    "                        entry = parts[0]\n",
    "                        pos = int(parts[1])\n",
    "                        embeddings = [float(x) for x in parts[2:]]\n",
    "                        if len(embeddings) != PROT_T5_DIM: skipped_count += 1; continue\n",
    "                        data_list.append((entry, pos, embeddings))\n",
    "                        loaded_count += 1\n",
    "                    except ValueError as e:\n",
    "                        print(f\"Error converting line {i+1} in {filepath}: {e}. Skipping.\")\n",
    "                        skipped_count += 1\n",
    "                    except Exception as e_inner:\n",
    "                        print(f\"Error processing line {i+1} in {filepath}: {e_inner}. Skipping.\")\n",
    "                        skipped_count += 1\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: ProtT5 file not found: {filepath}\")\n",
    "            return None, 0, 0 # Return None to indicate failure\n",
    "        except Exception as e_outer:\n",
    "            print(f\"Error reading {filepath}: {e_outer}\")\n",
    "            return None, 0, 0\n",
    "        return data_list, loaded_count, skipped_count\n",
    "\n",
    "    # Load positive and negative data\n",
    "    pos_data, loaded_pos, skipped_pos = _parse_emb_file(pos_file)\n",
    "    neg_data, loaded_neg, skipped_neg = _parse_emb_file(neg_file)\n",
    "\n",
    "    # Check if loading failed\n",
    "    if pos_data is None or neg_data is None:\n",
    "        return None, None\n",
    "\n",
    "    # Convert lists to dictionaries\n",
    "    pos_dict = {(entry, pos): emb for entry, pos, emb in pos_data}\n",
    "    neg_dict = {(entry, pos): emb for entry, pos, emb in neg_data}\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Loaded {loaded_pos} positive (skipped {skipped_pos}) and {loaded_neg} negative (skipped {skipped_neg}) ProtT5 embeddings.\")\n",
    "    print(f\"ProtT5 Loading finished in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "    return pos_dict, neg_dict\n",
    "\n",
    "\n",
    "def prepare_aligned_data(seq_struct_df: pd.DataFrame, pos_dict: Optional[Dict], neg_dict: Optional[Dict]) -> Tuple[np.ndarray, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Align ProtT5 embeddings with the main sequence/structure DataFrame.\n",
    "\n",
    "    Filters the input DataFrame to include only rows for which a\n",
    "    corresponding ProtT5 embedding exists in the provided dictionaries,\n",
    "    matching on ('entry', 'pos') and the row's 'label'.\n",
    "\n",
    "    Args:\n",
    "        seq_struct_df (pd.DataFrame): DataFrame containing sequence/structure info.\n",
    "                                      Must include 'entry', 'pos', and 'label' columns.\n",
    "        pos_dict (Optional[Dict]): Dictionary mapping (entry, pos) to positive embeddings.\n",
    "        neg_dict (Optional[Dict]): Dictionary mapping (entry, pos) to negative embeddings.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (X_prot_t5, aligned_df) where X_prot_t5 is a NumPy array of\n",
    "               aligned embeddings (shape [num_aligned, PROT_T5_DIM]) and\n",
    "               aligned_df is the filtered DataFrame containing only the rows\n",
    "               corresponding to the embeddings in X_prot_t5. Returns an empty\n",
    "               array and an empty DataFrame if alignment fails or inputs are invalid.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(\"Aligning ProtT5 embeddings with main DataFrame...\")\n",
    "    embeddings = []\n",
    "    aligned_indices = [] # Store original DataFrame indices of aligned rows\n",
    "    skipped_count = 0\n",
    "\n",
    "    # --- Input Validation ---\n",
    "    if pos_dict is None or neg_dict is None:\n",
    "        print(\"Error: Invalid ProtT5 dictionaries provided. Cannot align.\")\n",
    "        return np.array([]).reshape(0, PROT_T5_DIM), pd.DataFrame(columns=seq_struct_df.columns)\n",
    "\n",
    "    required_cols = ['entry', 'pos', 'label']\n",
    "    if not all(col in seq_struct_df.columns for col in required_cols):\n",
    "        print(f\"Error: Input DataFrame must contain columns: {required_cols}\")\n",
    "        return np.array([]).reshape(0, PROT_T5_DIM), pd.DataFrame(columns=seq_struct_df.columns)\n",
    "\n",
    "    # --- Alignment Loop ---\n",
    "    for idx, row in seq_struct_df.iterrows():\n",
    "        try:\n",
    "            # Ensure key components are correct type\n",
    "            key = (str(row['entry']), int(row['pos']))\n",
    "            label = int(row['label'])\n",
    "            emb_dict = pos_dict if label == 1 else neg_dict\n",
    "            emb = emb_dict.get(key)\n",
    "\n",
    "            if emb is not None:\n",
    "                if len(emb) == PROT_T5_DIM: # Final check on loaded dim\n",
    "                    embeddings.append(emb)\n",
    "                    aligned_indices.append(idx)\n",
    "                else: skipped_count += 1 # Dim mismatch\n",
    "            else: skipped_count += 1 # Key not found\n",
    "\n",
    "        except (TypeError, ValueError) as e:\n",
    "             print(f\"Warning: Skipping row index {idx} due to type error during key creation (entry='{row.get('entry')}', pos='{row.get('pos')}'): {e}\")\n",
    "             skipped_count += 1\n",
    "        except Exception as e_inner:\n",
    "             print(f\"Warning: Unexpected error processing row index {idx}: {e_inner}\")\n",
    "             skipped_count += 1\n",
    "\n",
    "    if skipped_count > 0:\n",
    "        print(f\"Alignment: Skipped {skipped_count} rows due to missing/invalid ProtT5 embeddings or data errors.\")\n",
    "    if not aligned_indices:\n",
    "        print(\"Error: No data points could be aligned with ProtT5 embeddings.\")\n",
    "        return np.array([]).reshape(0, PROT_T5_DIM), pd.DataFrame(columns=seq_struct_df.columns)\n",
    "\n",
    "    # --- Final Output Creation ---\n",
    "    X_prot_t5 = np.array(embeddings, dtype=np.float32)\n",
    "    aligned_df = seq_struct_df.loc[aligned_indices].copy() # Use .loc with original indices\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Alignment complete. Kept {len(aligned_df)} out of {len(seq_struct_df)} original rows.\")\n",
    "    print(f\"Alignment finished in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "    # Final dimension check\n",
    "    if X_prot_t5.shape[0] != len(aligned_df):\n",
    "         print(f\"CRITICAL WARNING: Mismatch after alignment! Embeddings: {X_prot_t5.shape[0]}, DataFrame: {len(aligned_df)}\")\n",
    "         return np.array([]).reshape(0, PROT_T5_DIM), pd.DataFrame(columns=seq_struct_df.columns) # Return empty on critical error\n",
    "\n",
    "    return X_prot_t5, aligned_df\n",
    "\n",
    "def create_edge_features(i_orig, j_orig, dist_map, sequence, ss_string, sasa_vals, K_POS=16):\n",
    "    \"\"\"\n",
    "    Create rich edge features (17 dims) between original indices i_orig and j_orig.\n",
    "    Handles padding checks.\n",
    "\n",
    "    Args:\n",
    "        i_orig, j_orig: Original 0-32 indices in the sequence window.\n",
    "        dist_map: Full 33x33 distance map numpy array.\n",
    "        sequence: Full 33-char sequence string.\n",
    "        ss_string: Full 33-char secondary structure string.\n",
    "        sasa_vals: Full 33-element SASA numpy array.\n",
    "        K_POS: Absolute index (0-32) of the central Lysine.\n",
    "\n",
    "    Returns:\n",
    "        A fixed-size numpy array (17,) dtype=np.float32.\n",
    "    \"\"\"\n",
    "    edge_features = np.zeros(EXPECTED_EDGE_FEATURE_DIM, dtype=np.float32) # Use corrected dimension (17)\n",
    "    seq_len = len(sequence) # Should be 33\n",
    "\n",
    "    # Basic validity and padding checks\n",
    "    if not (0 <= i_orig < seq_len and 0 <= j_orig < seq_len):\n",
    "        return edge_features\n",
    "    if sequence[i_orig] == '-' or sequence[j_orig] == '-':\n",
    "        return edge_features\n",
    "\n",
    "    # Safely get distance\n",
    "    distance = 0.0\n",
    "    if i_orig < dist_map.shape[0] and j_orig < dist_map.shape[1]:\n",
    "        distance = dist_map[i_orig, j_orig]\n",
    "    else:\n",
    "        return edge_features # Index out of bounds for dist_map\n",
    "\n",
    "    feature_idx = 0\n",
    "\n",
    "    # 1. Distance Features (5 features) - Bins + Inverse\n",
    "    if distance <= 0: pass # Handle zero/negative distance\n",
    "    elif distance <= 4.0: edge_features[feature_idx] = 1.0\n",
    "    elif distance <= 8.0: edge_features[feature_idx + 1] = 1.0\n",
    "    elif distance <= 12.0: edge_features[feature_idx + 2] = 1.0\n",
    "    else: edge_features[feature_idx + 3] = 1.0\n",
    "    feature_idx += 4\n",
    "    edge_features[feature_idx] = (1.0 / distance) if distance > 1e-6 else 0.0 # Inverse distance\n",
    "    feature_idx += 1\n",
    "\n",
    "    # 2. Sequential Features (2 features) - Neighbor + Normalized Distance\n",
    "    seq_dist = abs(i_orig - j_orig)\n",
    "    edge_features[feature_idx] = float(seq_dist == 1)\n",
    "    edge_features[feature_idx + 1] = seq_dist / max(1, seq_len - 1)\n",
    "    feature_idx += 2\n",
    "\n",
    "    # 3. K-relative Features (2 features) - Connected to K + Normalized Dist to K\n",
    "    edge_features[feature_idx] = float(i_orig == K_POS or j_orig == K_POS)\n",
    "    max_dist_from_k = max(1, K_POS, seq_len - 1 - K_POS)\n",
    "    edge_features[feature_idx + 1] = min(abs(i_orig - K_POS), abs(j_orig - K_POS)) / max_dist_from_k\n",
    "    feature_idx += 2\n",
    "\n",
    "    # 4. Secondary Structure Interaction (6 features)\n",
    "    if i_orig < len(ss_string) and j_orig < len(ss_string):\n",
    "        ss_pairs = ['HH', 'HE', 'HL', 'EE', 'EL', 'LL']\n",
    "        ss_map = {'H': 'H', 'E': 'E', 'L': 'L', '-': 'L'} # Map padding to Loop\n",
    "        ss_i = ss_map.get(ss_string[i_orig], 'L')\n",
    "        ss_j = ss_map.get(ss_string[j_orig], 'L')\n",
    "        ss_pair = ''.join(sorted([ss_i, ss_j]))\n",
    "        for idx, pair in enumerate(ss_pairs):\n",
    "            edge_features[feature_idx + idx] = float(ss_pair == pair)\n",
    "    feature_idx += 6\n",
    "\n",
    "    # 5. SASA Interaction (2 features) - Difference + Average\n",
    "    if i_orig < len(sasa_vals) and j_orig < len(sasa_vals):\n",
    "        sasa_i = np.nan_to_num(sasa_vals[i_orig])\n",
    "        sasa_j = np.nan_to_num(sasa_vals[j_orig])\n",
    "        edge_features[feature_idx] = abs(sasa_i - sasa_j)\n",
    "        edge_features[feature_idx + 1] = (sasa_i + sasa_j) / 2.0\n",
    "    feature_idx += 2\n",
    "\n",
    "    # Final check (optional)\n",
    "    # if feature_idx != EXPECTED_EDGE_FEATURE_DIM: print(\"Warning: Feature index mismatch\")\n",
    "\n",
    "    return np.nan_to_num(edge_features, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "# from torch_geometric.nn import GCNConv, GATv2Conv, PNAConv, GINEConv\n",
    "# from torch_geometric.utils import degree\n",
    "\n",
    "class GCNNetwork(nn.Module):\n",
    "    \"\"\" GNN Network using GCNConv layers (No edge features) \"\"\"\n",
    "    def __init__(self, input_dim: int, hidden_dim: int = 128, dropout: float = 0.4, layers: int = 3):\n",
    "        super().__init__()\n",
    "        if layers < 1: raise ValueError(\"GCN layers must be >= 1.\")\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        current_dim = input_dim\n",
    "        for i in range(layers):\n",
    "            self.convs.append(GCNConv(current_dim, hidden_dim))\n",
    "            self.batch_norms.append(nn.BatchNorm1d(hidden_dim))\n",
    "            current_dim = hidden_dim # Input for next layer is hidden_dim\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        self.num_layers = layers\n",
    "        self.output_dim = hidden_dim\n",
    "        print(f\"Initialized GCNNetwork: Layers={layers}, Hidden={hidden_dim}, Dropout={dropout}\")\n",
    "\n",
    "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" Forward pass for GCN. Returns all node features. \"\"\"\n",
    "        x_res = x # Initial input for potential residual connection\n",
    "        for i in range(self.num_layers):\n",
    "            # Store input features for residual connection (after first layer)\n",
    "            x_input = x if i > 0 else None\n",
    "\n",
    "            x = self.convs[i](x, edge_index)\n",
    "\n",
    "            # Apply Batch Normalization (check for nodes)\n",
    "            if x.shape[0] > 1: x = self.batch_norms[i](x)\n",
    "            elif x.shape[0] == 0: return x # Handle empty graph\n",
    "\n",
    "            x = F.relu(x) # Activation\n",
    "\n",
    "            # Apply Residual Connection\n",
    "            # Check if possible (not first layer) and shapes match\n",
    "            if x_input is not None and x.shape == x_input.shape:\n",
    "                x = x + x_input\n",
    "\n",
    "            x = self.dropout_layer(x) # Apply dropout\n",
    "\n",
    "        return x # Shape: [num_nodes, hidden_dim]\n",
    "\n",
    "class GATv2Network(nn.Module):\n",
    "    \"\"\" GNN Network using GATv2Conv (Optionally uses edge features) - Returns all node features \"\"\"\n",
    "    def __init__(self, input_dim: int, hidden_dim: int = 128, heads: int = 4, dropout: float = 0.4, layers: int = 3, edge_dim: Optional[int] = None):\n",
    "        super().__init__()\n",
    "        if layers < 1: raise ValueError(\"GATv2 layers must be >= 1.\")\n",
    "        if hidden_dim % heads != 0: raise ValueError(f\"GATv2 hidden_dim ({hidden_dim}) must be divisible by heads ({heads})\")\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        head_dim = hidden_dim // heads\n",
    "        # Flag to determine if edge_attr should be passed in forward\n",
    "        self.has_edge_features = edge_dim is not None and edge_dim > 0\n",
    "        current_dim = input_dim\n",
    "\n",
    "        # Layer Definitions\n",
    "        for i in range(layers):\n",
    "            conv_input_dim = current_dim if i == 0 else hidden_dim\n",
    "            # GATv2 output is concat=True, so output is hidden_dim (heads*head_dim)\n",
    "            self.convs.append(GATv2Conv(conv_input_dim, head_dim, heads=heads, concat=True,\n",
    "                                        dropout=dropout, edge_dim=edge_dim, add_self_loops=True))\n",
    "            self.batch_norms.append(nn.BatchNorm1d(hidden_dim))\n",
    "            current_dim = hidden_dim # Input dim for next layer is always hidden_dim\n",
    "\n",
    "        self.dropout_layer = nn.Dropout(dropout) # Dropout applied after activation/residual\n",
    "        self.num_layers = layers\n",
    "        self.output_dim = hidden_dim\n",
    "        print(f\"Initialized GATv2Network: Layers={layers}, Hidden={hidden_dim}, Heads={heads}, Dropout={dropout}, EdgeDim={edge_dim}\")\n",
    "\n",
    "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor, edge_attr: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        \"\"\" Forward pass for GATv2. Returns all node features. \"\"\"\n",
    "        x_res = x\n",
    "        for i in range(self.num_layers):\n",
    "            x_input = x if i > 0 else None # Store input for residual\n",
    "\n",
    "            # Pass edge_attr only if the model was initialized with edge_dim\n",
    "            if self.has_edge_features:\n",
    "                if edge_attr is None: raise ValueError(\"GATv2Network expects edge_attr but received None.\")\n",
    "                # Optional: Check edge_attr dim matches self.edge_dim if edge_dim was stored\n",
    "                x = self.convs[i](x, edge_index, edge_attr=edge_attr)\n",
    "            else:\n",
    "                x = self.convs[i](x, edge_index) # Call without edge_attr\n",
    "\n",
    "            # Apply Batch Normalization\n",
    "            if x.shape[0] > 1: x = self.batch_norms[i](x)\n",
    "            elif x.shape[0] == 0: return x\n",
    "\n",
    "            # Apply Activation (ELU common for GAT)\n",
    "            x = F.elu(x)\n",
    "\n",
    "            # Apply Residual Connection\n",
    "            if x_input is not None and x.shape == x_input.shape:\n",
    "                x = x + x_input\n",
    "\n",
    "            # Apply Dropout\n",
    "            x = self.dropout_layer(x)\n",
    "\n",
    "        return x # Shape: [num_nodes, hidden_dim]\n",
    "\n",
    "class PNANetwork(nn.Module):\n",
    "    \"\"\" GNN Network using PNAConv layers (No edge features) - Returns all node features \"\"\"\n",
    "    def __init__(self, input_dim: int, hidden_dim: int = 128, layers: int = 3, dropout: float = 0.4, deg: Optional[torch.Tensor] = None):\n",
    "        super().__init__()\n",
    "        if layers < 1: raise ValueError(\"PNA layers must be >= 1.\")\n",
    "        if deg is None: raise ValueError(\"PNANetwork requires the degree histogram 'deg' argument.\")\n",
    "\n",
    "        # PNA parameters (can be tuned)\n",
    "        aggregators = ['mean', 'min', 'max', 'std']\n",
    "        scalers = ['identity', 'amplification', 'attenuation']\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        current_dim = input_dim\n",
    "\n",
    "        # Layer Definitions\n",
    "        for i in range(layers):\n",
    "            conv_input_dim = current_dim if i == 0 else hidden_dim\n",
    "            # towers=4, post_layers=1 are common defaults/recommendations for PNA\n",
    "            self.convs.append(PNAConv(conv_input_dim, hidden_dim, aggregators=aggregators,\n",
    "                                      scalers=scalers, deg=deg, towers=4, post_layers=1))\n",
    "            self.batch_norms.append(nn.BatchNorm1d(hidden_dim))\n",
    "            current_dim = hidden_dim\n",
    "\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        self.num_layers = layers\n",
    "        self.output_dim = hidden_dim\n",
    "        print(f\"Initialized PNANetwork: Layers={layers}, Hidden={hidden_dim}, Dropout={dropout}\")\n",
    "\n",
    "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" Forward pass for PNA. Returns all node features. \"\"\"\n",
    "        x_res = x\n",
    "        for i in range(self.num_layers):\n",
    "            x_input = x if i > 0 else None\n",
    "\n",
    "            # Apply PNAConv (does not use edge_attr)\n",
    "            x = self.convs[i](x, edge_index)\n",
    "\n",
    "            # Apply Batch Normalization\n",
    "            if x.shape[0] > 1: x = self.batch_norms[i](x)\n",
    "            elif x.shape[0] == 0: return x\n",
    "\n",
    "            # Apply Activation\n",
    "            x = F.relu(x)\n",
    "\n",
    "            # Apply Residual Connection\n",
    "            if x_input is not None and x.shape == x_input.shape:\n",
    "                x = x + x_input\n",
    "\n",
    "            # Apply Dropout\n",
    "            x = self.dropout_layer(x)\n",
    "\n",
    "        return x # Shape: [num_nodes, hidden_dim]\n",
    "\n",
    "\n",
    "class GINENetwork(nn.Module):\n",
    "    \"\"\" GNN Network using GINEConv layers (Requires edge features) - Returns all node features \"\"\"\n",
    "    def __init__(self, input_dim: int, hidden_dim: int = 128, edge_dim: int = EXPECTED_EDGE_FEATURE_DIM, dropout: float = 0.4, layers: int = 3):\n",
    "        super().__init__()\n",
    "        if layers < 1: raise ValueError(\"GINE layers must be >= 1.\")\n",
    "        if edge_dim is None or edge_dim <= 0: raise ValueError(\"GINENetwork requires a valid positive 'edge_dim'.\")\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "        self.edge_dim = edge_dim # Store edge dim used\n",
    "        current_dim = input_dim\n",
    "\n",
    "        # Define the MLP for GINE's node update function 'nn'\n",
    "        def create_mlp(mlp_input_dim, mlp_output_dim):\n",
    "            # Simple 2-layer MLP used by GINE to update node features\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(mlp_input_dim, mlp_output_dim * 2), # Example expansion\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout), # Dropout within the MLP\n",
    "                nn.Linear(mlp_output_dim * 2, mlp_output_dim)\n",
    "            )\n",
    "\n",
    "        # Layer Definitions\n",
    "        for i in range(layers):\n",
    "            # The MLP inside GINE takes the current node dim as input\n",
    "            mlp_input_dim = current_dim if i == 0 else hidden_dim\n",
    "            mlp = create_mlp(mlp_input_dim, hidden_dim)\n",
    "            # train_eps=True allows the epsilon parameter in GIN update to be learned\n",
    "            self.convs.append(GINEConv(nn=mlp, edge_dim=self.edge_dim, train_eps=True))\n",
    "            self.batch_norms.append(nn.BatchNorm1d(hidden_dim))\n",
    "            current_dim = hidden_dim\n",
    "\n",
    "        self.dropout_layer = nn.Dropout(dropout) # Dropout after layer block\n",
    "        self.num_layers = layers\n",
    "        self.output_dim = hidden_dim\n",
    "        print(f\"Initialized GINENetwork: Layers={layers}, Hidden={hidden_dim}, Dropout={dropout}, EdgeDim={edge_dim}\")\n",
    "\n",
    "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor, edge_attr: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" Forward pass for GINE. Requires edge_attr. Returns all node features. \"\"\"\n",
    "        # x: [N, input_dim], edge_index: [2, E], edge_attr: [E, edge_dim]\n",
    "        if edge_attr is None:\n",
    "            raise ValueError(\"GINENetwork requires edge_attr for forward pass.\")\n",
    "        # Optional: Check edge_attr dimension matches self.edge_dim\n",
    "        if edge_attr.shape[1] != self.edge_dim:\n",
    "             raise ValueError(f\"GINENetwork edge_attr dim mismatch: Expected {self.edge_dim}, Got {edge_attr.shape[1]}\")\n",
    "\n",
    "        x_res = x\n",
    "        for i in range(self.num_layers):\n",
    "            x_input = x if i > 0 else None\n",
    "\n",
    "            # Apply GINEConv, passing edge_attr\n",
    "            x = self.convs[i](x, edge_index, edge_attr=edge_attr)\n",
    "\n",
    "            # Apply Batch Normalization\n",
    "            if x.shape[0] > 1: x = self.batch_norms[i](x)\n",
    "            elif x.shape[0] == 0: return x\n",
    "\n",
    "            # Apply Activation\n",
    "            x = F.relu(x)\n",
    "\n",
    "            # Apply Residual Connection\n",
    "            if x_input is not None and x.shape == x_input.shape:\n",
    "                x = x + x_input\n",
    "\n",
    "            # Apply Dropout\n",
    "            x = self.dropout_layer(x)\n",
    "\n",
    "        return x # Shape: [num_nodes, hidden_dim]\n",
    "\n",
    "\n",
    "class HybridModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Hybrid model combining features from a chosen GNN backbone\n",
    "    (using GNN readout: Central + Mean + Max) and a processed ProtT5 embedding\n",
    "    via late fusion for binary classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, gnn_type: str, node_feature_dim: int, hidden_dim: int = 128,\n",
    "                 prot_t5_dim: int = PROT_T5_DIM, # From constants\n",
    "                 # --- GNN specific args (passed via model_config in train function) ---\n",
    "                 deg: Optional[torch.Tensor] = None, # Required for PNA\n",
    "                 edge_dim: Optional[int] = None,     # Used by GATv2/GINE if provided\n",
    "                 heads: int = 4,                     # Default heads for GATv2\n",
    "                 # --- Common GNN hyperparams ---\n",
    "                 layers: int = 3,\n",
    "                 gnn_dropout: float = 0.4,           # Dropout for GNN layers\n",
    "                 # --- ProtT5 MLP hyperparams ---\n",
    "                 pt5_mlp_dropout: float = 0.4,\n",
    "                 # --- Final Classifier hyperparams ---\n",
    "                 classifier_dropout: float = 0.5):\n",
    "        \"\"\"\n",
    "        Initializes the Hybrid GNN+ProtT5 Model.\n",
    "\n",
    "        Args:\n",
    "            gnn_type (str): Type of GNN backbone ('gcn', 'gatv2', 'pna', 'gine').\n",
    "            node_feature_dim (int): Dimensionality of input node features for GNN.\n",
    "            hidden_dim (int): Hidden dimension for GNN layers.\n",
    "            prot_t5_dim (int): Dimensionality of input ProtT5 embeddings.\n",
    "            deg (Optional[torch.Tensor]): Degree histogram tensor, REQUIRED for 'pna'.\n",
    "            edge_dim (Optional[int]): Edge feature dimension. Used by 'gatv2'/'gine' if provided.\n",
    "                                     Should match EXPECTED_EDGE_FEATURE_DIM if used.\n",
    "            heads (int): Number of attention heads for 'gatv2'.\n",
    "            layers (int): Number of layers in the GNN backbone.\n",
    "            gnn_dropout (float): Dropout rate within the GNN backbone layers.\n",
    "            pt5_mlp_dropout (float): Dropout rate within the ProtT5 MLP.\n",
    "            classifier_dropout (float): Dropout rate in the final classifier MLP.\n",
    "        \"\"\"\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.gnn_type = gnn_type.lower()\n",
    "        # Determine if edge features are needed based on GNN type and edge_dim argument\n",
    "        self.use_edge_features = edge_dim is not None and self.gnn_type in ['gatv2', 'gine']\n",
    "        print(f\"Initializing HybridModel (GNN={self.gnn_type.upper()} + ProtT5)\")\n",
    "        if self.use_edge_features:\n",
    "             print(f\"  GNN configured to use edge features (dim={edge_dim})\")\n",
    "        else:\n",
    "             print(f\"  GNN configured NOT to use edge features.\")\n",
    "\n",
    "\n",
    "        # --- GNN Backbone Instantiation ---\n",
    "        gnn_common_args = {\n",
    "            'input_dim': node_feature_dim, 'hidden_dim': hidden_dim,\n",
    "            'dropout': gnn_dropout, 'layers': layers\n",
    "        }\n",
    "        try:\n",
    "            if self.gnn_type == 'gcn':\n",
    "                self.gnn = GCNNetwork(**gnn_common_args)\n",
    "            elif self.gnn_type == 'gatv2':\n",
    "                # Pass edge_dim (can be None), pass heads\n",
    "                self.gnn = GATv2Network(**gnn_common_args, heads=heads, edge_dim=edge_dim)\n",
    "            elif self.gnn_type == 'pna':\n",
    "                if deg is None: raise ValueError(\"PNA requires the 'deg' histogram argument.\")\n",
    "                self.gnn = PNANetwork(**gnn_common_args, deg=deg)\n",
    "            elif self.gnn_type == 'gine':\n",
    "                if edge_dim is None: raise ValueError(\"GINE requires the 'edge_dim' argument.\")\n",
    "                # Ensure passed edge_dim matches expected if necessary\n",
    "                if edge_dim != EXPECTED_EDGE_FEATURE_DIM:\n",
    "                    print(f\"Warning: GINE edge_dim ({edge_dim}) differs from expected ({EXPECTED_EDGE_FEATURE_DIM}).\")\n",
    "                self.gnn = GINENetwork(**gnn_common_args, edge_dim=edge_dim)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported GNN type: {gnn_type}\")\n",
    "        except Exception as e:\n",
    "             print(f\"--- ERROR during GNN Backbone ({self.gnn_type.upper()}) Initialization ---\")\n",
    "             print(e)\n",
    "             traceback.print_exc()\n",
    "             raise e # Re-raise after printing\n",
    "\n",
    "        # Get the output dimension from the instantiated GNN\n",
    "        gnn_output_dim = self.gnn.output_dim\n",
    "\n",
    "\n",
    "        # --- ProtT5 Track Initialization ---\n",
    "        # Simple MLP to process the ProtT5 embedding before fusion\n",
    "        pt5_mlp_hidden = 256 # Example hidden size for ProtT5 MLP\n",
    "        prot_t5_output_dim = 128 # Final dimension after ProtT5 MLP\n",
    "        self.prot_t5_mlp = nn.Sequential(\n",
    "            nn.Linear(prot_t5_dim, pt5_mlp_hidden),\n",
    "            # Consider BatchNorm1d? nn.BatchNorm1d(pt5_mlp_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(pt5_mlp_dropout),\n",
    "            nn.Linear(pt5_mlp_hidden, prot_t5_output_dim),\n",
    "            # Consider BatchNorm1d? nn.BatchNorm1d(prot_t5_output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(pt5_mlp_dropout)\n",
    "            # No final activation here, combined then classified\n",
    "        )\n",
    "        print(f\"  ProtT5 MLP initialized: {prot_t5_dim} -> ... -> {prot_t5_output_dim}\")\n",
    "\n",
    "\n",
    "        # --- Combination and Final Classifier ---\n",
    "        # Input dimension = GNN Central + GNN Mean + GNN Max + Processed ProtT5\n",
    "        combined_input_dim = gnn_output_dim + gnn_output_dim + gnn_output_dim + prot_t5_output_dim\n",
    "        print(f\"  Combined input dimension for final classifier: {combined_input_dim}\")\n",
    "\n",
    "        # Final classification layers (MLP head)\n",
    "        classifier_hidden = 64 # Example hidden size\n",
    "        self.fc1 = nn.Linear(combined_input_dim, classifier_hidden)\n",
    "        self.bn_combine = nn.BatchNorm1d(classifier_hidden) # Renamed BN layer\n",
    "        self.dropout_combine = nn.Dropout(classifier_dropout) # Renamed Dropout layer\n",
    "        self.fc2 = nn.Linear(classifier_hidden, 1) # Final binary output\n",
    "\n",
    "        print(\"HybridModel initialization complete.\")\n",
    "\n",
    "\n",
    "    def forward(self, data: Batch) -> torch.Tensor:\n",
    "        \"\"\" Forward pass of the HybridModel (GNN + ProtT5). \"\"\"\n",
    "        # --- Input Extraction ---\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        # Edge attributes are needed only if self.use_edge_features is True\n",
    "        edge_attr = data.edge_attr if self.use_edge_features and hasattr(data, 'edge_attr') else None\n",
    "        batch = data.batch # Maps each node to its graph index in the batch\n",
    "        central_node_idx = data.central_node_idx # Relative index within each graph's valid nodes\n",
    "        ptr = data.ptr if hasattr(data, 'ptr') else None # Graph start/end pointers\n",
    "\n",
    "        # Get ProtT5 embedding - check it exists\n",
    "        if not hasattr(data, 'prot_t5_embedding'):\n",
    "             raise AttributeError(\"Batch object missing 'prot_t5_embedding'. Check data preparation.\")\n",
    "        prot_t5_emb = data.prot_t5_embedding # Shape: [batch_size, prot_t5_dim]\n",
    "\n",
    "        # Reconstruct ptr from batch if missing (e.g., single inference)\n",
    "        if ptr is None and batch is not None:\n",
    "             if batch.numel() > 0: counts = torch.bincount(batch); ptr = torch.cat([torch.tensor([0], device=batch.device), counts.cumsum(0)])\n",
    "             else: ptr = torch.tensor([0], device=batch.device)\n",
    "\n",
    "        # Essential check for pooling/indexing logic downstream\n",
    "        if batch is None or ptr is None or central_node_idx is None:\n",
    "             raise ValueError(\"HybridModel forward requires 'batch', 'ptr', and 'central_node_idx' attributes.\")\n",
    "\n",
    "        batch_size = data.num_graphs\n",
    "        if batch_size == 0: # Handle empty batch early\n",
    "            # print(\"Warning: HybridModel forward received empty batch (num_graphs=0).\")\n",
    "            return torch.zeros((0, 1), device=x.device if x is not None else device, dtype=torch.float)\n",
    "\n",
    "        # Validate ProtT5 shape against batch_size\n",
    "        if prot_t5_emb.shape[0] != batch_size or prot_t5_emb.shape[1] != PROT_T5_DIM:\n",
    "             raise ValueError(f\"ProtT5 embedding shape mismatch! Expected ({batch_size}, {PROT_T5_DIM}), Got {prot_t5_emb.shape}\")\n",
    "\n",
    "        # --- ProtT5 Track ---\n",
    "        prot_t5_features = self.prot_t5_mlp(prot_t5_emb) # Shape: [batch_size, prot_t5_output_dim]\n",
    "\n",
    "        # --- GNN Track ---\n",
    "        # Call the selected GNN backbone\n",
    "        # Pass edge_attr only if the model is configured to use them\n",
    "        if self.use_edge_features:\n",
    "             if edge_attr is None:\n",
    "                 raise ValueError(f\"Model '{self.gnn_type}' requires edge_attr but not found in data.\")\n",
    "             # Check edge_attr feature dimension if it exists\n",
    "             if edge_index.shape[1] > 0: # Only check if edges exist\n",
    "                 if edge_attr.shape[0] != edge_index.shape[1]:\n",
    "                     raise ValueError(f\"Edge attribute count ({edge_attr.shape[0]}) != edge index count ({edge_index.shape[1]})\")\n",
    "                 # Optional: Check dimension match with model's expectation if edge_dim was stored\n",
    "                 # if edge_attr.shape[1] != self.gnn.edge_dim: # Requires GNNs to store edge_dim\n",
    "                 #     raise ValueError(f\"Edge attribute dim mismatch.\")\n",
    "             gnn_node_features = self.gnn(x, edge_index, edge_attr=edge_attr)\n",
    "        else:\n",
    "             # Pass only x and edge_index (GCN, PNA, GATv2 w/o edge_dim)\n",
    "             gnn_node_features = self.gnn(x, edge_index)\n",
    "\n",
    "\n",
    "        # --- GNN Readout (Central Node + Global Pooling) ---\n",
    "        # Initialize readout tensors robustly\n",
    "        gnn_output_dim = self.gnn.output_dim\n",
    "        central_node_features = torch.zeros((batch_size, gnn_output_dim), device=x.device, dtype=x.dtype)\n",
    "        global_avg_features = torch.zeros((batch_size, gnn_output_dim), device=x.device, dtype=x.dtype)\n",
    "        global_max_features = torch.zeros((batch_size, gnn_output_dim), device=x.device, dtype=x.dtype)\n",
    "\n",
    "        # Perform readout only if GNN output is valid\n",
    "        num_nodes = gnn_node_features.shape[0] if gnn_node_features is not None else 0\n",
    "        nodes_exist = num_nodes > 0\n",
    "        # Indices/batch vector must also be valid for readout\n",
    "        indices_valid = ptr.numel() > 1 and central_node_idx.numel() == batch_size and \\\n",
    "                        batch.numel() > 0 and batch.max() < batch_size\n",
    "\n",
    "        if nodes_exist and indices_valid:\n",
    "            try:\n",
    "                # Extract Central Node Features\n",
    "                graph_starts = ptr[:-1]\n",
    "                absolute_central_node_indices = graph_starts + central_node_idx\n",
    "                if absolute_central_node_indices.max() < num_nodes and absolute_central_node_indices.min() >= 0:\n",
    "                     central_node_features = gnn_node_features[absolute_central_node_indices]\n",
    "                # else: print(f\"Warning: Readout - Central index bounds.\") # Debug\n",
    "\n",
    "                # Global Pooling\n",
    "                if batch.numel() == num_nodes: # Ensure batch vector matches nodes\n",
    "                     global_avg_features = global_mean_pool(gnn_node_features, batch)\n",
    "                     global_max_features = global_max_pool(gnn_node_features, batch)\n",
    "                # else: print(f\"Warning: Readout - Batch vector length mismatch.\") # Debug\n",
    "\n",
    "            except Exception as e_readout:\n",
    "                 print(f\"Error during GNN readout: {e_readout}. Using zero features.\")\n",
    "                 # Keep initialized zero tensors\n",
    "\n",
    "        # elif batch_size > 0 : print(f\"Warning: Skipping GNN readout.\") # Debug\n",
    "\n",
    "        # --- Combine Features ---\n",
    "        # Concatenate: GNN Central + GNN Mean + GNN Max + Processed ProtT5\n",
    "        # Ensure all components have the correct batch size dimension\n",
    "        feature_list = [central_node_features, global_avg_features, global_max_features, prot_t5_features]\n",
    "        correct_batch_size = True\n",
    "        for i, feat in enumerate(feature_list):\n",
    "            if feat.shape[0] != batch_size:\n",
    "                print(f\"Error: Feature {i} has wrong batch size before concat. Expected {batch_size}, Got {feat.shape}\")\n",
    "                correct_batch_size = False\n",
    "                break\n",
    "\n",
    "        if not correct_batch_size:\n",
    "            # Handle error state - cannot concatenate reliably\n",
    "            print(\"FATAL: Cannot combine features due to shape mismatch. Returning zeros.\")\n",
    "            return torch.zeros((batch_size, 1), device=x.device, dtype=torch.float)\n",
    "\n",
    "        # Concatenate the features\n",
    "        combined = torch.cat(feature_list, dim=1)\n",
    "\n",
    "        # --- Final Classification MLP ---\n",
    "        x_out = self.fc1(combined)\n",
    "        if x_out.shape[0] > 1: # Apply BN only if batch size > 1\n",
    "            x_out = self.bn_combine(x_out)\n",
    "        # Handle case where batch size is 1 (BN would fail) or combination resulted in empty tensor\n",
    "        elif x_out.shape[0] == 0:\n",
    "             return torch.zeros((batch_size, 1), device=x.device, dtype=torch.float)\n",
    "\n",
    "        x_out = F.relu(x_out)\n",
    "        x_out = self.dropout_combine(x_out)\n",
    "        x_out = self.fc2(x_out) # Shape: [batch_size, 1]\n",
    "\n",
    "        # Apply sigmoid for binary classification probability\n",
    "        return torch.sigmoid(x_out)\n",
    "\n",
    "\n",
    "def prepare_graph_data(\n",
    "    df_aligned: pd.DataFrame,\n",
    "    prot_t5_embeddings: np.ndarray,\n",
    "    distance_threshold: float = 8.0,\n",
    "    use_ss_node_feature: bool = True, # Flag to include SS one-hot in node features\n",
    "    include_edge_features: bool = False # Flag to create/include 17-dim edge_attr\n",
    "    ) -> Tuple[List[Data], List[int]]:\n",
    "    \"\"\"\n",
    "    Prepare graph Data objects for PyTorch Geometric using the ALIGNED DataFrame\n",
    "    and corresponding ProtT5 embeddings, tailored for the GNN+ProtT5 Hybrid Model.\n",
    "\n",
    "    Extracts node features (AA, central K, angles, SASA, SS, pLDDT).\n",
    "    Constructs graph edges based on distance.\n",
    "    Optionally generates 17-dim edge features if include_edge_features=True.\n",
    "    Adds the ProtT5 embedding for the central K to each Data object.\n",
    "    Does NOT store the full sequence string in the final Data object.\n",
    "\n",
    "    Args:\n",
    "        df_aligned (pd.DataFrame): DataFrame ALIGNED with prot_t5_embeddings.\n",
    "                                   Requires sequence and structural feature columns.\n",
    "        prot_t5_embeddings (np.ndarray): NumPy array of ProtT5 embeddings, ordered\n",
    "                                          corresponding to df_aligned rows.\n",
    "                                          Shape: [num_aligned, PROT_T5_DIM].\n",
    "        distance_threshold (float): Max C-alpha distance for graph edges.\n",
    "        use_ss_node_feature (bool): Whether to include SS one-hot in node features.\n",
    "        include_edge_features (bool): Whether to generate and include edge_attr.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (graph_list, labels)\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(f\"Preparing PyG graph data (GNN+ProtT5 format: Edge Feats={include_edge_features}, SS Node={use_ss_node_feature}) for {len(df_aligned)} aligned samples...\")\n",
    "    graph_list = []\n",
    "    labels = []\n",
    "    skipped_count = 0\n",
    "    parse_errors, concat_errors, edge_errors, validation_errors = 0, 0, 0, 0\n",
    "\n",
    "    # --- Pre-check Alignment ---\n",
    "    if len(df_aligned) != prot_t5_embeddings.shape[0] or prot_t5_embeddings.shape[1] != PROT_T5_DIM:\n",
    "         raise ValueError(\"Critical Setup Error: Mismatch between aligned df and ProtT5 embeddings dimensions.\")\n",
    "\n",
    "    # --- Define features to parse from the DataFrame ---\n",
    "    # Ensure all columns needed for node features AND edge features (if used) are listed\n",
    "    feature_names_to_parse = [\n",
    "        'phi', 'psi', 'omega', 'tau', 'chi1', 'chi2', 'chi3', 'chi4', # All angles\n",
    "        'sasa', 'ss', 'plDDT', # SASA, SS, pLDDT\n",
    "        'distance_map', # Essential for edges\n",
    "        'sequence', # Essential for AA features, edge features, validation\n",
    "    ]\n",
    "    print(f\"  Will attempt to parse features: {feature_names_to_parse}\")\n",
    "\n",
    "\n",
    "    # --- Iterate through aligned data ---\n",
    "    # Using enumerate to get index 'i' for accessing prot_t5_embeddings[i]\n",
    "    for i, (original_idx, row) in enumerate(df_aligned.iterrows()):\n",
    "        try:\n",
    "            # --- Basic Data Retrieval & Validation ---\n",
    "            sequence = row.get('sequence') # Needed for AA features, padding checks, edge features\n",
    "            label = row.get('label')\n",
    "            if pd.isna(sequence) or len(sequence) != EXPECTED_SEQ_LEN or sequence[CENTRAL_K_POS_ABS] != 'K' or pd.isna(label):\n",
    "                 skipped_count += 1; continue\n",
    "            label = int(label)\n",
    "\n",
    "            # Get the corresponding ProtT5 embedding (pre-aligned)\n",
    "            current_prot_t5_embedding_np = prot_t5_embeddings[i] # Shape (PROT_T5_DIM,)\n",
    "\n",
    "            # --- Parse Structural Features ---\n",
    "            parsed_data = {}\n",
    "            valid_row = True\n",
    "            for name in feature_names_to_parse:\n",
    "                if name == 'sequence': # Already have sequence\n",
    "                    parsed_data[name] = sequence\n",
    "                    continue\n",
    "                if name not in row or pd.isna(row[name]):\n",
    "                     if name == 'distance_map': valid_row = False; break # Essential\n",
    "                     else: parsed_data[name] = np.nan # Placeholder for optional features\n",
    "                else:\n",
    "                    try: # Parse data safely\n",
    "                        feature_str = str(row[name])\n",
    "                        if name == 'ss': parsed_data[name] = feature_str; assert len(parsed_data[name]) == EXPECTED_SEQ_LEN\n",
    "                        else:\n",
    "                            parsed_arr = np.array(eval(feature_str), dtype=np.float32)\n",
    "                            if name == 'distance_map':\n",
    "                                if parsed_arr.size == EXPECTED_SEQ_LEN*EXPECTED_SEQ_LEN: parsed_data[name] = parsed_arr.reshape(EXPECTED_SEQ_LEN, EXPECTED_SEQ_LEN)\n",
    "                                else: raise ValueError(\"Distmap size mismatch\")\n",
    "                            elif parsed_arr.ndim == 1 and len(parsed_arr) != EXPECTED_SEQ_LEN: # Handle 1D length mismatch\n",
    "                                temp_arr = np.full(EXPECTED_SEQ_LEN, np.nan, dtype=np.float32); L = min(len(parsed_arr), EXPECTED_SEQ_LEN); temp_arr[:L] = parsed_arr[:L]; parsed_data[name] = temp_arr\n",
    "                            else: parsed_data[name] = parsed_arr\n",
    "                    except Exception as e:\n",
    "                        # print(f\"Parsing error for {name}, row {original_idx}: {e}\") # Debug\n",
    "                        valid_row = False; parse_errors += 1; break\n",
    "            if not valid_row: skipped_count += 1; continue\n",
    "            # Ensure essential parsed data exists\n",
    "            distance_map = parsed_data.get('distance_map')\n",
    "            ss_full = parsed_data.get('ss', '-' * EXPECTED_SEQ_LEN) # Default if missing\n",
    "            sasa_full = parsed_data.get('sasa', np.full(EXPECTED_SEQ_LEN, np.nan)) # Default if missing\n",
    "            if distance_map is None: skipped_count += 1; continue\n",
    "\n",
    "\n",
    "            # --- Identify Valid Nodes ---\n",
    "            valid_pos_indices = [k for k, aa in enumerate(sequence) if aa in VALID_AA]\n",
    "            if not valid_pos_indices: skipped_count += 1; continue\n",
    "            num_nodes = len(valid_pos_indices)\n",
    "            try: central_k_new_idx = valid_pos_indices.index(CENTRAL_K_POS_ABS)\n",
    "            except ValueError: skipped_count += 1; continue # Central K was padded\n",
    "\n",
    "\n",
    "            # --- Node Feature Extraction ---\n",
    "            # Collect all node features required by the GNN track\n",
    "            node_features_list = []\n",
    "            # 1. AA One-hot (20 features)\n",
    "            aa_onehot = np.zeros((num_nodes, len(VALID_AA)), dtype=np.float32);\n",
    "            for k, node_idx in enumerate(valid_pos_indices): aa = sequence[node_idx]; aa_idx = VALID_AA.find(aa);\n",
    "            if aa_idx >= 0: aa_onehot[k, aa_idx] = 1.0\n",
    "            node_features_list.append(aa_onehot)\n",
    "            # 2. Central K indicator (1 feature)\n",
    "            is_central_k = np.zeros((num_nodes, 1), dtype=np.float32); is_central_k[central_k_new_idx, 0] = 1.0\n",
    "            node_features_list.append(is_central_k)\n",
    "            # 3. Angles (phi, psi, omega, tau, chi1-4) -> sin/cos (8 * 2 = 16 features)\n",
    "            angle_keys = ['phi', 'psi', 'omega']\n",
    "            for key in angle_keys:\n",
    "                 if key in parsed_data and isinstance(parsed_data[key], np.ndarray):\n",
    "                     valid_angles = np.nan_to_num(parsed_data[key][valid_pos_indices], nan=0.0) # Fill NaN angles with 0\n",
    "                     angle_rad = np.pi * valid_angles / 180.0\n",
    "                     sin_cos = np.stack([np.sin(angle_rad), np.cos(angle_rad)], axis=-1)\n",
    "                     node_features_list.append(sin_cos.astype(np.float32))\n",
    "                 else: node_features_list.append(np.zeros((num_nodes, 2), dtype=np.float32)) # Zeros if missing\n",
    "            # 4. SASA (1 feature)\n",
    "            # if 'sasa' in parsed_data and isinstance(parsed_data['sasa'], np.ndarray):\n",
    "            #     valid_sasa = np.nan_to_num(parsed_data['sasa'][valid_pos_indices], nan=0.0).reshape(-1, 1)\n",
    "            #     node_features_list.append(valid_sasa.astype(np.float32))\n",
    "            # else: node_features_list.append(np.zeros((num_nodes, 1), dtype=np.float32))\n",
    "            # # 5. SS (Secondary Structure) (3 features if use_ss_node_feature=True)\n",
    "            # if use_ss_node_feature and 'ss' in parsed_data and isinstance(parsed_data['ss'], str):\n",
    "            #      ss_string_feat = parsed_data['ss']; valid_ss_chars = [ss_string_feat[k] for k in valid_pos_indices]\n",
    "            #      ss_onehot = np.zeros((num_nodes, 3), dtype=np.float32); ss_map = {'H': 0, 'E': 1, 'L': 2, '-': 2} # Add other SS codes if present\n",
    "            #      for k, ss_char in enumerate(valid_ss_chars): ss_onehot[k, ss_map.get(ss_char.upper(), 2)] = 1.0\n",
    "            #      node_features_list.append(ss_onehot)\n",
    "            # elif use_ss_node_feature: node_features_list.append(np.zeros((num_nodes, 3), dtype=np.float32))\n",
    "            # # 6. pLDDT (1 feature, scaled 0-1)\n",
    "            # if 'plDDT' in parsed_data and isinstance(parsed_data['plDDT'], np.ndarray):\n",
    "            #     valid_plddt = np.nan_to_num(parsed_data['plDDT'][valid_pos_indices], nan=50.0).reshape(-1, 1) # Fill NaN pLDDT?\n",
    "            #     node_features_list.append((valid_plddt / 100.0).astype(np.float32)) # Scale 0-1\n",
    "            # else: node_features_list.append(np.zeros((num_nodes, 1), dtype=np.float32))\n",
    "            # --- Concatenate Node Features ---\n",
    "            try:\n",
    "                 if not node_features_list: raise ValueError(\"Node feature list empty.\")\n",
    "                 node_features = np.concatenate(node_features_list, axis=1)\n",
    "                 if np.isnan(node_features).any() or np.isinf(node_features).any():\n",
    "                      node_features = np.nan_to_num(node_features, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            except ValueError as e: skipped_count += 1; concat_errors += 1; continue\n",
    "\n",
    "\n",
    "            # --- Edge Construction & Optional Feature Extraction ---\n",
    "            edge_features_list = [] # Reset for each graph\n",
    "            edge_attr_tensor = None\n",
    "            try:\n",
    "                valid_distance_map = distance_map[np.ix_(valid_pos_indices, valid_pos_indices)]\n",
    "                adj = (valid_distance_map < distance_threshold) & (valid_distance_map > 0); np.fill_diagonal(adj, False)\n",
    "                edge_list_valid = np.argwhere(adj) # Indices relative to valid nodes\n",
    "                edges = []\n",
    "                if edge_list_valid.shape[0] > 0:\n",
    "                    edges = edge_list_valid.tolist()\n",
    "                    if include_edge_features:\n",
    "                        for i_valid, j_valid in edges:\n",
    "                            i_orig = valid_pos_indices[i_valid]; j_orig = valid_pos_indices[j_valid]\n",
    "                            # Pass sequence string parsed earlier\n",
    "                            edge_feat_vec = create_edge_features(i_orig, j_orig, distance_map, sequence, ss_full, sasa_full)\n",
    "                            edge_features_list.append(edge_feat_vec)\n",
    "\n",
    "                # Fallback Sequential Edges\n",
    "                if not edges and num_nodes > 1:\n",
    "                     for k_valid in range(num_nodes - 1):\n",
    "                         edges.extend([[k_valid, k_valid+1], [k_valid+1, k_valid]])\n",
    "                         if include_edge_features:\n",
    "                             i_orig = valid_pos_indices[k_valid]; j_orig = valid_pos_indices[k_valid+1]\n",
    "                             feat1 = create_edge_features(i_orig, j_orig, distance_map, sequence, ss_full, sasa_full)\n",
    "                             feat2 = create_edge_features(j_orig, i_orig, distance_map, sequence, ss_full, sasa_full)\n",
    "                             edge_features_list.extend([feat1, feat2])\n",
    "\n",
    "                if not edges: skipped_count += 1; edge_errors += 1; continue # Skip if still no edges\n",
    "\n",
    "                # Convert edge features to tensor if needed and generated\n",
    "                if include_edge_features and edge_features_list:\n",
    "                    edge_attr_np = np.array(edge_features_list, dtype=np.float32)\n",
    "                    if edge_attr_np.shape[0] == len(edges) and edge_attr_np.shape[1] == EXPECTED_EDGE_FEATURE_DIM:\n",
    "                         edge_attr_tensor = torch.tensor(edge_attr_np, dtype=torch.float)\n",
    "                    # else: Print warning about mismatch (less verbose)\n",
    "\n",
    "            except Exception as e: skipped_count += 1; edge_errors += 1; continue\n",
    "\n",
    "\n",
    "            # --- Convert to Tensors ---\n",
    "            try:\n",
    "                x_tensor = torch.tensor(node_features, dtype=torch.float)\n",
    "                edge_index_tensor = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "                y_tensor = torch.tensor([label], dtype=torch.float)\n",
    "                central_node_idx_tensor = torch.tensor([central_k_new_idx], dtype=torch.long)\n",
    "                # ProtT5 tensor - unsqueeze to add batch-like dimension [1, Dim]\n",
    "                prot_t5_tensor = torch.tensor(current_prot_t5_embedding_np, dtype=torch.float).unsqueeze(0)\n",
    "                # --- Final Check for ProtT5 Shape ---\n",
    "                if prot_t5_tensor.shape != (1, PROT_T5_DIM):\n",
    "                     print(f\"Warning: ProtT5 tensor shape incorrect ({prot_t5_tensor.shape}) for row {original_idx}. Skipping.\")\n",
    "                     skipped_count += 1; continue\n",
    "            except Exception as e: skipped_count += 1; continue\n",
    "\n",
    "\n",
    "            # --- Create PyG Data object ---\n",
    "            data_dict = {\n",
    "                'x': x_tensor,\n",
    "                'edge_index': edge_index_tensor,\n",
    "                'y': y_tensor,\n",
    "                'central_node_idx': central_node_idx_tensor,\n",
    "                'prot_t5_embedding': prot_t5_tensor # ADD T5 embedding here\n",
    "                # NO 'sequence' attribute added\n",
    "            }\n",
    "            # Conditionally add edge_attr tensor if it was successfully created\n",
    "            if edge_attr_tensor is not None:\n",
    "                data_dict['edge_attr'] = edge_attr_tensor\n",
    "\n",
    "            data = Data(**data_dict)\n",
    "\n",
    "            # --- Validate Data Object ---\n",
    "            if not data.validate(raise_on_error=False): # Raise error for debugging if needed\n",
    "                 skipped_count += 1; validation_errors += 1; continue\n",
    "\n",
    "            graph_list.append(data)\n",
    "            labels.append(label)\n",
    "\n",
    "        # --- Catch errors for the entire row processing ---\n",
    "        except Exception as e_outer:\n",
    "            print(f\"--- Critical Error processing aligned row index {i} (original index {original_idx}): {e_outer} ---\")\n",
    "            traceback.print_exc(limit=2); skipped_count += 1\n",
    "            continue\n",
    "\n",
    "    # --- Final Summary ---\n",
    "    end_time = time.time()\n",
    "    print(f\"\\nGraph Preparation Summary:\") # ... (print summary counts as before) ...\n",
    "    print(f\"  Created {len(graph_list)} graphs from {len(df_aligned)} aligned samples.\")\n",
    "    print(f\"  Skipped {skipped_count} rows (ParseErr={parse_errors}, ConcatErr={concat_errors}, EdgeErr={edge_errors}, ValidErr={validation_errors}, Other={skipped_count-(parse_errors+concat_errors+edge_errors+validation_errors)}).\")\n",
    "    if graph_list:\n",
    "         print(f\"  Example graph node feature dimension: {graph_list[0].num_node_features}\")\n",
    "         edge_feat_dim_str = str(graph_list[0].num_edge_features) if graph_list[0].edge_attr is not None else 'N/A'\n",
    "         print(f\"  Example graph edge feature dimension: {edge_feat_dim_str}\")\n",
    "         print(f\"  Example ProtT5 embedding dimension: {graph_list[0].prot_t5_embedding.shape}\")\n",
    "    print(f\"Graph preparation finished in {end_time - start_time:.2f} seconds.\")\n",
    "    return graph_list, labels\n",
    "\n",
    "\n",
    "def train_model(model: nn.Module, loader: DataLoader, optimizer: torch.optim.Optimizer,\n",
    "                device: torch.device, class_weights: Optional[Dict] = None) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Trains the model for one epoch. Handles GNN+ProtT5 HybridModel input.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The PyTorch model (HybridModel) to train.\n",
    "        loader (DataLoader): DataLoader for the training data.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer to use.\n",
    "        device (torch.device): The device (CPU or CUDA) to train on.\n",
    "        class_weights (Optional[Dict]): Dict mapping class index (0, 1) to weight.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (average_loss_per_sample, accuracy) for the epoch.\n",
    "    \"\"\"\n",
    "    model.train() # Set the model to training mode\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    processed_graphs = 0\n",
    "    skipped_batches = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        try:\n",
    "            batch = batch.to(device)\n",
    "\n",
    "            # --- Batch Validation ---\n",
    "            # Check essential attributes needed by HybridModel (GNN+ProtT5)\n",
    "            required_attrs = ['x', 'edge_index', 'prot_t5_embedding', 'y', 'batch', 'central_node_idx']\n",
    "            # edge_attr is optional depending on the GNN used within HybridModel\n",
    "            if not all(hasattr(batch, attr) and getattr(batch, attr) is not None for attr in required_attrs):\n",
    "                print(f\"Warning: Skipping training batch due to missing essential attributes: {[attr for attr in required_attrs if not hasattr(batch, attr) or getattr(batch, attr) is None]}\")\n",
    "                skipped_batches += 1\n",
    "                continue\n",
    "            # Skip batches with no nodes or no graphs (can happen with filtering/edge cases)\n",
    "            if batch.num_nodes == 0 or batch.num_graphs == 0:\n",
    "                skipped_batches += 1\n",
    "                continue\n",
    "\n",
    "            # --- Forward Pass ---\n",
    "            optimizer.zero_grad() # Clear previous gradients\n",
    "            output = model(batch) # Get model predictions (should be sigmoid output)\n",
    "\n",
    "            # --- Target Preparation ---\n",
    "            target = batch.y.view(-1, 1).float() # Ensure target shape [batch_size, 1] and type\n",
    "\n",
    "            # Check if output and target shapes match after potential filtering/empty graphs\n",
    "            if output.shape[0] != target.shape[0] or output.shape[1] != 1:\n",
    "                print(f\"Warning: Shape mismatch output ({output.shape}) vs target ({target.shape}). Skipping batch.\")\n",
    "                skipped_batches += 1\n",
    "                continue\n",
    "            if target.numel() == 0: # Skip if target is empty\n",
    "                skipped_batches += 1\n",
    "                continue\n",
    "\n",
    "            # --- Loss Calculation ---\n",
    "            weight_tensor = None\n",
    "            if class_weights is not None:\n",
    "                try: # Create weight tensor safely\n",
    "                    target_long = target.long()\n",
    "                    if ((target_long == 0) | (target_long == 1)).all(): # Check labels are 0 or 1\n",
    "                         weights_list = [class_weights[k.item()] for k in target_long]\n",
    "                         weight_tensor = torch.tensor(weights_list, device=device, dtype=torch.float).view(-1, 1)\n",
    "                    # else: Skip weighting if labels invalid (warning printed if needed)\n",
    "                except KeyError as e: print(f\"Warning: Invalid target label {e} for class weights.\")\n",
    "                except Exception as e_w: print(f\"Warning: Error creating class weights: {e_w}\")\n",
    "\n",
    "            # Calculate Binary Cross-Entropy loss\n",
    "            current_loss = F.binary_cross_entropy(output, target, weight=weight_tensor, reduction='sum')\n",
    "\n",
    "            # Check for NaN/Inf loss\n",
    "            if not torch.isfinite(current_loss):\n",
    "                print(f\"Warning: Non-finite loss ({current_loss.item()}) detected. Skipping batch.\")\n",
    "                skipped_batches += 1; continue\n",
    "\n",
    "            # --- Backward Pass and Optimization ---\n",
    "            current_loss.backward()\n",
    "            # Optional: Gradient Clipping\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            # --- Accumulate Metrics ---\n",
    "            total_loss += current_loss.item() # Accumulate summed loss\n",
    "            with torch.no_grad():\n",
    "                 pred = (output > 0.5).float()\n",
    "                 correct_predictions += (pred == target).sum().item()\n",
    "                 total_samples += target.size(0) # Count samples processed\n",
    "                 processed_graphs += batch.num_graphs\n",
    "\n",
    "        # --- Error Handling for Batch ---\n",
    "        except Exception as e:\n",
    "            print(f\"--- Error during training batch: {type(e).__name__} - {e} ---\")\n",
    "            traceback.print_exc(limit=1) # Show where error occurred\n",
    "            skipped_batches += 1; continue # Skip to next batch\n",
    "\n",
    "    # --- Epoch Summary ---\n",
    "    if skipped_batches > 0:\n",
    "        print(f\"Skipped {skipped_batches} batches during training epoch.\")\n",
    "\n",
    "    # Calculate average loss PER SAMPLE and accuracy for the epoch\n",
    "    if total_samples > 0:\n",
    "        average_loss_per_sample = total_loss / total_samples\n",
    "        accuracy = correct_predictions / total_samples\n",
    "    else:\n",
    "        print(\"Warning: No samples processed in training epoch.\")\n",
    "        average_loss_per_sample = 0.0\n",
    "        accuracy = 0.0\n",
    "\n",
    "    return average_loss_per_sample, accuracy\n",
    "\n",
    "\n",
    "def evaluate_model(model: nn.Module, loader: DataLoader, device: torch.device) -> dict:\n",
    "    \"\"\"\n",
    "    Evaluates the HybridModel on a given dataset (validation or test).\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The PyTorch model to evaluate.\n",
    "        loader (DataLoader): DataLoader for the evaluation data.\n",
    "        device (torch.device): The device (CPU or CUDA) to evaluate on.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing evaluation metrics (loss, accuracy, mcc, etc.).\n",
    "    \"\"\"\n",
    "    model.eval() # Set the model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    all_preds_list = [] # Store prediction arrays from batches\n",
    "    all_targets_list = [] # Store target arrays from batches\n",
    "    processed_samples = 0\n",
    "    skipped_batches = 0\n",
    "\n",
    "    # Disable gradient calculations during evaluation\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            try:\n",
    "                batch = batch.to(device)\n",
    "                # --- Batch Validation ---\n",
    "                required_attrs = ['x', 'edge_index', 'prot_t5_embedding', 'y', 'batch', 'central_node_idx']\n",
    "                if not all(hasattr(batch, attr) and getattr(batch, attr) is not None for attr in required_attrs):\n",
    "                     skipped_batches += 1; continue\n",
    "                if batch.num_nodes == 0 or batch.num_graphs == 0:\n",
    "                     skipped_batches += 1; continue\n",
    "\n",
    "                # --- Forward Pass ---\n",
    "                output = model(batch) # Get model prediction probabilities\n",
    "                target = batch.y.view(-1, 1).float() # Ensure shape and type\n",
    "\n",
    "                if output.shape[0] != target.shape[0] or output.shape[1] != 1:\n",
    "                    skipped_batches += 1; continue\n",
    "                if target.numel() == 0:\n",
    "                    skipped_batches += 1; continue\n",
    "\n",
    "                # --- Loss Calculation ---\n",
    "                loss = F.binary_cross_entropy(output, target, reduction='sum')\n",
    "                if not torch.isfinite(loss):\n",
    "                    print(f\"Warning: Non-finite loss ({loss.item()}) during evaluation. Skipping batch metrics.\")\n",
    "                    skipped_batches += 1; continue\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                # --- Store Predictions and Targets ---\n",
    "                pred_binary = (output > 0.5).float() # Threshold at 0.5 for metrics\n",
    "                all_preds_list.append(pred_binary.cpu().numpy())\n",
    "                all_targets_list.append(target.cpu().numpy())\n",
    "                processed_samples += target.size(0)\n",
    "\n",
    "            # --- Error Handling for Batch ---\n",
    "            except Exception as e:\n",
    "                print(f\"--- Error during evaluation batch: {type(e).__name__} - {e} ---\")\n",
    "                traceback.print_exc(limit=1); skipped_batches += 1; continue\n",
    "\n",
    "    if skipped_batches > 0: print(f\"Skipped {skipped_batches} batches during evaluation.\")\n",
    "\n",
    "    # --- Calculate Metrics ---\n",
    "    # Initialize metrics dictionary with defaults\n",
    "    metrics = {\n",
    "        'loss': float('nan'), 'accuracy': 0.0, 'balanced_acc': 0.0, 'mcc': 0.0,\n",
    "        'sensitivity': 0.0, 'specificity': 0.0, 'confusion_matrix': np.zeros((2,2), dtype=int),\n",
    "        'predictions': np.array([]), 'targets': np.array([]) # Store concatenated arrays\n",
    "    }\n",
    "\n",
    "    if not all_preds_list: # Handle case where no batches were successfully processed\n",
    "        print(\"Warning: No predictions collected during evaluation.\")\n",
    "        return metrics\n",
    "\n",
    "    # Concatenate results from all batches\n",
    "    all_preds = np.concatenate(all_preds_list).flatten()\n",
    "    all_targets = np.concatenate(all_targets_list).flatten()\n",
    "    metrics['predictions'] = all_preds # Store final binary predictions\n",
    "    metrics['targets'] = all_targets\n",
    "\n",
    "    if processed_samples > 0:\n",
    "        metrics['loss'] = total_loss / processed_samples # Average loss per sample\n",
    "        try:\n",
    "            metrics['accuracy'] = accuracy_score(all_targets, all_preds)\n",
    "            metrics['balanced_acc'] = balanced_accuracy_score(all_targets, all_preds)\n",
    "            # Handle MCC undefined case (e.g., constant predictions)\n",
    "            try: metrics['mcc'] = matthews_corrcoef(all_targets, all_preds)\n",
    "            except ValueError: metrics['mcc'] = 0.0\n",
    "\n",
    "            cm = confusion_matrix(all_targets, all_preds, labels=[0, 1])\n",
    "            metrics['confusion_matrix'] = cm\n",
    "            if cm.shape == (2, 2):\n",
    "                tn, fp, fn, tp = cm.ravel()\n",
    "                metrics['sensitivity'] = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "                metrics['specificity'] = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "        except Exception as e_metrics:\n",
    "            print(f\"Error calculating evaluation metrics: {e_metrics}\")\n",
    "            # Metrics will keep their default zero values\n",
    "    else:\n",
    "        print(\"Warning: Processed samples count is zero after evaluation loop.\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def print_metrics(metrics: dict, prefix: str = \"\"):\n",
    "    \"\"\" Prints evaluation metrics in a formatted way. \"\"\"\n",
    "    print(f\"{prefix}Loss: {metrics.get('loss', float('nan')):.4f}\")\n",
    "    print(f\"{prefix}Accuracy: {metrics.get('accuracy', float('nan')):.4f}\")\n",
    "    print(f\"{prefix}Balanced Acc: {metrics.get('balanced_acc', float('nan')):.4f}\")\n",
    "    print(f\"{prefix}MCC: {metrics.get('mcc', float('nan')):.4f}\")\n",
    "    print(f\"{prefix}Sensitivity: {metrics.get('sensitivity', float('nan')):.4f}\")\n",
    "    print(f\"{prefix}Specificity: {metrics.get('specificity', float('nan')):.4f}\")\n",
    "    print(f\"{prefix}Confusion Matrix:\")\n",
    "    cm = metrics.get('confusion_matrix')\n",
    "    if isinstance(cm, np.ndarray) and cm.shape == (2,2):\n",
    "        print(f\"  [[TN={cm[0,0]:<5d} FP={cm[0,1]:<5d}]\")\n",
    "        print(f\"   [FN={cm[1,0]:<5d} TP={cm[1,1]:<5d}]]\")\n",
    "    else:\n",
    "        print(f\"  {cm}\") # Print CM as is if not standard 2x2 numpy array\n",
    "\n",
    "\n",
    "def train_and_evaluate_hybrid_model(\n",
    "    train_df_aligned: pd.DataFrame, train_prot_t5: np.ndarray,\n",
    "    test_df_aligned: pd.DataFrame, test_prot_t5: np.ndarray,\n",
    "    model_config: Dict, # Contains GNN type, hypers, flags like use_edge_features\n",
    "    distance_threshold: float = 8.0,\n",
    "    n_splits: int = 5\n",
    "    ) -> Tuple[Optional[Dict], Optional[Dict]]:\n",
    "    \"\"\"\n",
    "    Trains and evaluates a single Hybrid GNN+ProtT5 model configuration using K-fold CV.\n",
    "\n",
    "    Args:\n",
    "        train_df_aligned (pd.DataFrame): Aligned training DataFrame.\n",
    "        train_prot_t5 (np.ndarray): ProtT5 embeddings for the aligned training data.\n",
    "        test_df_aligned (pd.DataFrame): Aligned testing DataFrame.\n",
    "        test_prot_t5 (np.ndarray): ProtT5 embeddings for the aligned testing data.\n",
    "        model_config (dict): Configuration dictionary including 'gnn_type',\n",
    "                             'use_edge_features', and hyperparameters.\n",
    "        distance_threshold (float): Distance cutoff for graph edges.\n",
    "        n_splits (int): Number of folds for cross-validation.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (avg_cv_metrics, final_test_metrics)\n",
    "            - avg_cv_metrics (Optional[Dict]): Dictionary of average validation metrics across CV folds.\n",
    "            - final_test_metrics (Optional[Dict]): Dictionary of metrics on the test set using ensemble.\n",
    "    \"\"\"\n",
    "    gnn_type = model_config['gnn_type']\n",
    "    use_edge_features = model_config.get('use_edge_features', False)\n",
    "    run_label = f\"Hybrid {gnn_type.upper()}+ProtT5 (Edge Feats: {use_edge_features})\"\n",
    "    print(f\"\\n{'='*15} Evaluating: {run_label} {'='*15}\")\n",
    "    cv_start_time = time.time()\n",
    "\n",
    "    # --- Data Preparation (using function from Block 5) ---\n",
    "    # Pass use_ss_node_feature based on config or default\n",
    "    use_ss_node = model_config.get('use_ss_node_feature', True)\n",
    "    print(f\"Preparing graph data (SS Node Features: {use_ss_node}, Edge Features: {use_edge_features})...\")\n",
    "    train_graphs, train_labels = prepare_graph_data(\n",
    "        train_df_aligned, train_prot_t5, distance_threshold,\n",
    "        use_ss_node_feature=use_ss_node,\n",
    "        include_edge_features=use_edge_features\n",
    "    )\n",
    "    # Prepare test graphs if test data exists\n",
    "    has_test_data = not test_df_aligned.empty and len(test_prot_t5) > 0\n",
    "    test_graphs: List[Data] = []\n",
    "    test_labels: List[int] = [] # Get labels from aligned df for evaluation\n",
    "    if has_test_data:\n",
    "        test_graphs, test_labels = prepare_graph_data(\n",
    "            test_df_aligned, test_prot_t5, distance_threshold,\n",
    "            use_ss_node_feature=use_ss_node,\n",
    "            include_edge_features=use_edge_features\n",
    "        )\n",
    "        if not test_graphs: has_test_data = False # Update flag if failed\n",
    "    if not train_graphs:\n",
    "        print(f\"ERROR: No training graphs created for {run_label}. Aborting run.\")\n",
    "        return None, None\n",
    "\n",
    "    # --- Compute Degree Histogram for PNA (if needed) ---\n",
    "    deg_histogram = None\n",
    "    if gnn_type.lower() == 'pna':\n",
    "        print(\"Calculating node degree histogram for PNA (from training graphs)...\")\n",
    "        # Use the robust degree calculation logic from previous versions\n",
    "        max_degree = -1; degrees = []\n",
    "        for data in train_graphs:\n",
    "             num_nodes = data.num_nodes\n",
    "             if num_nodes == 0: continue\n",
    "             if hasattr(data, 'edge_index') and data.edge_index is not None and data.edge_index.numel() > 0:\n",
    "                 valid_mask = (data.edge_index[0] < num_nodes) & (data.edge_index[1] < num_nodes)\n",
    "                 valid_idx = data.edge_index[:, valid_mask]\n",
    "                 if valid_idx.numel() > 0: deg_list = degree(valid_idx[1], num_nodes=num_nodes, dtype=torch.long)\n",
    "                 else: deg_list = torch.zeros(num_nodes, dtype=torch.long)\n",
    "             else: deg_list = torch.zeros(num_nodes, dtype=torch.long)\n",
    "             degrees.append(deg_list)\n",
    "             if deg_list.numel() > 0: max_degree = max(max_degree, deg_list.max().item())\n",
    "        if max_degree == -1: max_degree = 0\n",
    "        # Ensure histogram size is at least 1\n",
    "        deg_histogram = torch.zeros(max_degree + 1, dtype=torch.long)\n",
    "        if degrees:\n",
    "            all_degrees = torch.cat(degrees, dim=0)\n",
    "            if all_degrees.numel() > 0:\n",
    "                counts = torch.bincount(all_degrees, minlength=max_degree + 1)\n",
    "                copy_len = min(deg_histogram.numel(), counts.numel())\n",
    "                deg_histogram[:copy_len] = counts[:copy_len]\n",
    "        print(f\"PNA Max degree: {max_degree}\")\n",
    "        if deg_histogram.sum() == 0 and deg_histogram.numel() > 0:\n",
    "            print(\"Warning: PNA Degree histogram is all zeros. Providing minimal.\")\n",
    "            deg_histogram[0] = 1 # Assign count 1 to degree 0 if all else fails\n",
    "        deg_histogram = deg_histogram.to(device) # Move histogram to target device\n",
    "\n",
    "    # --- Class Weights ---\n",
    "    total_train = len(train_labels); pos_train = sum(train_labels); neg_train = total_train - pos_train\n",
    "    class_weights_dict = {0: total_train / (2 * neg_train) if neg_train > 0 else 1.0,\n",
    "                          1: total_train / (2 * pos_train) if pos_train > 0 else 1.0}\n",
    "    print(f\"Calculated Class weights: {class_weights_dict}\")\n",
    "\n",
    "    # --- Cross-validation Setup ---\n",
    "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    fold_metrics_list: List[Dict] = []\n",
    "    test_predictions_list: List[np.ndarray] = [] # Store binary predictions from test set\n",
    "\n",
    "    # Determine feature dimensions from data\n",
    "    try:\n",
    "        node_feature_dim = train_graphs[0].num_node_features\n",
    "        # Determine edge_dim based on data only if model requires it\n",
    "        edge_dim_arg = None\n",
    "        if use_edge_features:\n",
    "            first_graph_with_edges = next((g for g in train_graphs if hasattr(g, 'edge_attr') and g.edge_attr is not None), None)\n",
    "            if first_graph_with_edges is not None:\n",
    "                edge_dim_arg = first_graph_with_edges.num_edge_features\n",
    "                if edge_dim_arg != EXPECTED_EDGE_FEATURE_DIM:\n",
    "                     print(f\"Warning: Data edge_dim ({edge_dim_arg}) != Expected ({EXPECTED_EDGE_FEATURE_DIM}). Using data dim.\")\n",
    "            else: # Edge features requested but none found in data\n",
    "                 if gnn_type == 'gine': # GINE requires edge features\n",
    "                      print(\"ERROR: GINE requires edge features, but none generated/found in training data.\")\n",
    "                      return None, None\n",
    "                 print(f\"Warning: use_edge_features=True for {gnn_type} but no 'edge_attr' found. Proceeding without edge features.\")\n",
    "                 edge_dim_arg = None # Fallback to no edge features\n",
    "        print(f\"Feature dimensions used for model init: Nodes={node_feature_dim}, Edges={edge_dim_arg}\")\n",
    "    except (IndexError, AttributeError) as e:\n",
    "        print(f\"ERROR: Cannot determine feature dimensions from train_graphs: {e}. Aborting.\")\n",
    "        return None, None\n",
    "\n",
    "    # --- K-Fold Loop ---\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(np.zeros(len(train_graphs)), train_labels), 1):\n",
    "        fold_start_time = time.time()\n",
    "        print(f\"\\n===== Fold {fold}/{n_splits} =====\")\n",
    "        train_fold_graphs = [train_graphs[i] for i in train_idx]\n",
    "        val_fold_graphs = [train_graphs[i] for i in val_idx]\n",
    "        print(f\"  Training samples: {len(train_fold_graphs)}, Validation samples: {len(val_fold_graphs)}\")\n",
    "\n",
    "        # DataLoaders\n",
    "        batch_size = model_config.get('batch_size', 32)\n",
    "        num_workers = 2 if device.type == 'cuda' else 0; pin_memory = torch.cuda.is_available()\n",
    "        train_loader = DataLoader(train_fold_graphs, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory)\n",
    "        val_loader = DataLoader(val_fold_graphs, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "        # --- Model Initialization ---\n",
    "        try:\n",
    "            model = HybridModel(\n",
    "                gnn_type=gnn_type,\n",
    "                node_feature_dim=node_feature_dim,\n",
    "                hidden_dim=model_config.get('hidden_dim', 128),\n",
    "                prot_t5_dim=PROT_T5_DIM, # Constant\n",
    "                # GNN specific args\n",
    "                deg=deg_histogram if gnn_type == 'pna' else None,\n",
    "                edge_dim=edge_dim_arg, # Pass determined/required edge dim\n",
    "                heads=model_config.get('heads', 4),\n",
    "                # Common GNN hypers\n",
    "                layers=model_config.get('layers', 3),\n",
    "                gnn_dropout=model_config.get('gnn_dropout', 0.4),\n",
    "                # ProtT5 MLP hypers\n",
    "                pt5_mlp_dropout=model_config.get('pt5_mlp_dropout', 0.4),\n",
    "                # Classifier hypers\n",
    "                classifier_dropout=model_config.get('classifier_dropout', 0.5)\n",
    "            ).to(device)\n",
    "        except Exception as model_init_error:\n",
    "             print(f\"--- ERROR initializing Hybrid Model for fold {fold}: {model_init_error} ---\")\n",
    "             traceback.print_exc(); continue # Skip this fold\n",
    "\n",
    "        # --- Optimizer and Scheduler ---\n",
    "        # optimizer = torch.optim.AdamW(model.parameters(), # Using AdamW\n",
    "        #                               lr=model_config.get('lr', 0.001),\n",
    "        #                               weight_decay=model_config.get('weight_decay', 0.01))\n",
    "        optimizer = torch.optim.Adam(model.parameters(), # Match old code\n",
    "                              lr=model_config.get('lr', 0.001),\n",
    "                              weight_decay=model_config.get('weight_decay', 0.01))\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=model_config.get('scheduler_patience', 5), verbose=False, min_lr=1e-6)\n",
    "\n",
    "        # --- Training Loop ---\n",
    "        epochs = model_config.get('epochs', 50); patience = model_config.get('patience', 10)\n",
    "        best_val_loss = float('inf'); epochs_no_improve = 0; best_state_dict = None\n",
    "        print(f\"  Starting training for max {epochs} epochs (Patience: {patience})...\")\n",
    "        for epoch in range(epochs):\n",
    "            train_loss, train_acc = train_model(model, train_loader, optimizer, device, class_weights=class_weights_dict)\n",
    "            val_metrics = evaluate_model(model, val_loader, device)\n",
    "            val_loss = val_metrics.get('loss', float('inf')) # Get loss safely\n",
    "\n",
    "            scheduler.step(val_loss)\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "            # Optional: Print epoch progress less frequently\n",
    "            if (epoch + 1) % 5 == 0 or epoch == 0 or epoch == epochs - 1:\n",
    "                 print(f\"  Epoch {epoch+1:02d}/{epochs} | Tr L:{train_loss:.4f}, A:{train_acc:.4f} | V L:{val_loss:.4f}, BAcc:{val_metrics['balanced_acc']:.4f} | LR:{current_lr:.1e}\")\n",
    "\n",
    "            # Early stopping check\n",
    "            if val_loss < best_val_loss:\n",
    "                 best_val_loss = val_loss; epochs_no_improve = 0; best_state_dict = model.state_dict().copy()\n",
    "            else:\n",
    "                 epochs_no_improve += 1\n",
    "                 if epochs_no_improve >= patience: print(f\"  Early stopping triggered at epoch {epoch+1}. Best val loss: {best_val_loss:.4f}\"); break\n",
    "        # --- End Epoch Loop ---\n",
    "\n",
    "        # Load best model state for fold evaluation\n",
    "        if best_state_dict is not None: model.load_state_dict(best_state_dict)\n",
    "        else: print(\"  Warning: No improvement found / No best model state saved. Using last state.\"); # Should only happen if training fails instantly\n",
    "\n",
    "        # Evaluate best model on validation set\n",
    "        print(f\"\\n  Evaluating best model on validation set for Fold {fold}...\")\n",
    "        final_val_metrics = evaluate_model(model, val_loader, device)\n",
    "        fold_metrics_list.append(final_val_metrics)\n",
    "        print_metrics(final_val_metrics, prefix=f\"  Fold {fold} Validation \")\n",
    "\n",
    "        # Evaluate best model on test set (if data exists)\n",
    "        if has_test_data and test_graphs:\n",
    "            print(f\"  Predicting on test set using Fold {fold}'s best model...\")\n",
    "            # Use a potentially larger batch size for inference\n",
    "            test_loader = DataLoader(test_graphs, batch_size=batch_size*2, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
    "            test_fold_eval_metrics = evaluate_model(model, test_loader, device)\n",
    "            if 'predictions' in test_fold_eval_metrics and isinstance(test_fold_eval_metrics['predictions'], np.ndarray):\n",
    "                 test_predictions_list.append(test_fold_eval_metrics['predictions']) # Store binary predictions\n",
    "            # else: print(f\"  Warning: Invalid 'predictions' from test eval fold {fold}.\") # Less verbose\n",
    "\n",
    "        fold_end_time = time.time()\n",
    "        print(f\"===== Fold {fold} completed in {fold_end_time - fold_start_time:.2f} seconds =====\")\n",
    "    # --- End Fold Loop ---\n",
    "\n",
    "    # --- Aggregate and Report CV Results ---\n",
    "    print(f\"\\n--- Cross-validation Summary for {run_label} (Avg +/- Std Dev on Val Folds) ---\")\n",
    "    avg_cv_metrics: Optional[Dict] = None\n",
    "    if fold_metrics_list:\n",
    "        metrics_to_report = ['loss', 'accuracy', 'balanced_acc', 'mcc', 'sensitivity', 'specificity']\n",
    "        avg_metrics_calc = {}\n",
    "        for metric in metrics_to_report:\n",
    "            values = [m.get(metric) for m in fold_metrics_list if m and m.get(metric) is not None and np.isfinite(m.get(metric))]\n",
    "            if values:\n",
    "                 avg_metrics_calc[metric] = np.mean(values)\n",
    "                 std_dev = np.std(values)\n",
    "                 print(f\"  Avg Val {metric:<15}: {avg_metrics_calc[metric]:.4f}  {std_dev:.4f}\")\n",
    "            else: avg_metrics_calc[metric] = None; print(f\"  Avg Val {metric:<15}: N/A\")\n",
    "        avg_cv_metrics = avg_metrics_calc # Store the calculated dict\n",
    "    else: print(\"  No metrics recorded from cross-validation folds.\")\n",
    "\n",
    "    # --- Final Test Set Evaluation (Ensembled) ---\n",
    "    final_test_metrics: Optional[Dict] = None\n",
    "    if has_test_data and test_predictions_list and test_labels is not None and len(test_labels) > 0:\n",
    "        print(f\"\\n--- Final Test Set Performance for {run_label} (Ensemble: Majority Vote) ---\")\n",
    "        try:\n",
    "             num_test = len(test_labels)\n",
    "             valid_preds = [p for p in test_predictions_list if isinstance(p, np.ndarray) and len(p) == num_test]\n",
    "             if len(valid_preds) != n_splits: print(f\"Warning: Number of valid test predictions ({len(valid_preds)}) != n_splits ({n_splits}).\")\n",
    "\n",
    "             if valid_preds: # Proceed only if valid predictions exist\n",
    "                test_pred_stack = np.stack(valid_preds, axis=0) # [n_folds, n_samples]\n",
    "                # Majority vote based on binary predictions\n",
    "                summed_preds = np.sum(test_pred_stack, axis=0)\n",
    "                threshold = len(valid_preds) / 2.0\n",
    "                test_pred_ensemble_binary = (summed_preds > threshold).astype(int)\n",
    "\n",
    "                # Calculate final metrics\n",
    "                final_test_metrics = {}\n",
    "                final_test_metrics['targets'] = np.array(test_labels) # Store labels for reference\n",
    "                final_test_metrics['predictions'] = test_pred_ensemble_binary # Store final ensemble prediction\n",
    "                final_test_metrics['accuracy'] = accuracy_score(test_labels, test_pred_ensemble_binary)\n",
    "                final_test_metrics['balanced_acc'] = balanced_accuracy_score(test_labels, test_pred_ensemble_binary)\n",
    "                try: final_test_metrics['mcc'] = matthews_corrcoef(test_labels, test_pred_ensemble_binary)\n",
    "                except ValueError: final_test_metrics['mcc'] = 0.0\n",
    "                final_test_metrics['confusion_matrix'] = confusion_matrix(test_labels, test_pred_ensemble_binary, labels=[0, 1])\n",
    "                cm = final_test_metrics['confusion_matrix']\n",
    "                sens, spec = 0.0, 0.0\n",
    "                if cm.shape == (2, 2): tn, fp, fn, tp = cm.ravel(); sens = tp / (tp + fn) if (tp + fn) > 0 else 0.0; spec = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "                final_test_metrics['sensitivity'] = sens; final_test_metrics['specificity'] = spec\n",
    "                # Assign loss from avg CV metrics for reporting consistency\n",
    "                final_test_metrics['loss'] = avg_cv_metrics.get('loss', float('nan')) if avg_cv_metrics else float('nan')\n",
    "\n",
    "                print_metrics(final_test_metrics, prefix=\"Ensemble Test \")\n",
    "             else: print(\"  Skipping test ensemble: No valid predictions available from folds.\")\n",
    "        except Exception as e_ensemble: print(f\"Error during test set ensembling/evaluation: {e_ensemble}\"); traceback.print_exc(limit=2)\n",
    "    # else: print reason why test eval skipped (handled earlier)\n",
    "\n",
    "    cv_end_time = time.time()\n",
    "    print(f\"\\n--- Evaluation for {run_label} completed in {cv_end_time - cv_start_time:.2f} seconds ---\")\n",
    "\n",
    "    # Return the aggregated results for this run\n",
    "    return avg_cv_metrics, final_test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781ede1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- File Paths Used ---\n",
      "Train CSV: /home/ubuntu/data/hai/thesis/training_code/data/processed_features_fixed_train_contactmap.csv\n",
      "Test CSV: /home/ubuntu/data/hai/thesis/training_code/data/processed_features_fixed_test_contactmap.csv\n",
      "Train ProtT5 (+): /home/ubuntu/data/hai/thesis/data/train/features/train_positive_ProtT5-XL-UniRef50.csv\n",
      "-----------------------\n",
      "\n",
      "Loading main feature CSV data...\n",
      "Loaded 8853 training, 2737 test samples from CSV.\n",
      "Loading ProtT5 data...\n",
      "  Positive file: ../../data/train/features/train_positive_ProtT5-XL-UniRef50.csv\n",
      "  Negative file: ../../data/train/features/train_negative_ProtT5-XL-UniRef50.csv\n",
      "Loaded 4750 positive (skipped 0) and 4750 negative (skipped 0) ProtT5 embeddings.\n",
      "ProtT5 Loading finished in 2.16 seconds.\n",
      "Loading ProtT5 data...\n",
      "  Positive file: ../../data/test/features/test_positive_ProtT5-XL-UniRef50.csv\n",
      "  Negative file: ../../data/test/features/test_negative_ProtT5-XL-UniRef50.csv\n",
      "Loaded 253 positive (skipped 0) and 2972 negative (skipped 0) ProtT5 embeddings.\n",
      "ProtT5 Loading finished in 0.76 seconds.\n",
      "\n",
      "Aligning training data...\n",
      "Aligning ProtT5 embeddings with main DataFrame...\n",
      "Alignment complete. Kept 8853 out of 8853 original rows.\n",
      "Alignment finished in 0.69 seconds.\n",
      "\n",
      "Aligning test data...\n",
      "Aligning ProtT5 embeddings with main DataFrame...\n",
      "Alignment complete. Kept 2737 out of 2737 original rows.\n",
      "Alignment finished in 0.21 seconds.\n",
      "\n",
      "--- Aligned Data Shapes ---\n",
      "Train DF: (8853, 16), Train ProtT5: (8853, 1024)\n",
      "Test DF : (2737, 16), Test ProtT5 : (2737, 1024)\n",
      "--------------------------\n",
      "\n",
      "\n",
      "=============== Evaluating: Hybrid GCN+ProtT5 (Edge Feats: False) ===============\n",
      "Preparing graph data (SS Node Features: True, Edge Features: False)...\n",
      "Preparing PyG graph data (GNN+ProtT5 format: Edge Feats=False, SS Node=True) for 8853 aligned samples...\n",
      "  Will attempt to parse features: ['phi', 'psi', 'omega', 'tau', 'chi1', 'chi2', 'chi3', 'chi4', 'sasa', 'ss', 'plDDT', 'distance_map', 'sequence']\n",
      "\n",
      "Graph Preparation Summary:\n",
      "  Created 8853 graphs from 8853 aligned samples.\n",
      "  Skipped 0 rows (ParseErr=0, ConcatErr=0, EdgeErr=0, ValidErr=0, Other=0).\n",
      "  Example graph node feature dimension: 27\n",
      "  Example graph edge feature dimension: N/A\n",
      "  Example ProtT5 embedding dimension: torch.Size([1, 1024])\n",
      "Graph preparation finished in 30.60 seconds.\n",
      "Preparing PyG graph data (GNN+ProtT5 format: Edge Feats=False, SS Node=True) for 2737 aligned samples...\n",
      "  Will attempt to parse features: ['phi', 'psi', 'omega', 'tau', 'chi1', 'chi2', 'chi3', 'chi4', 'sasa', 'ss', 'plDDT', 'distance_map', 'sequence']\n",
      "\n",
      "Graph Preparation Summary:\n",
      "  Created 2737 graphs from 2737 aligned samples.\n",
      "  Skipped 0 rows (ParseErr=0, ConcatErr=0, EdgeErr=0, ValidErr=0, Other=0).\n",
      "  Example graph node feature dimension: 27\n",
      "  Example graph edge feature dimension: N/A\n",
      "  Example ProtT5 embedding dimension: torch.Size([1, 1024])\n",
      "Graph preparation finished in 9.03 seconds.\n",
      "Calculated Class weights: {0: 1.0388406477352734, 1: 0.9639590592334495}\n",
      "Feature dimensions used for model init: Nodes=27, Edges=None\n",
      "\n",
      "===== Fold 1/5 =====\n",
      "  Training samples: 7082, Validation samples: 1771\n",
      "Initializing HybridModel (GNN=GCN + ProtT5)\n",
      "  GNN configured NOT to use edge features.\n",
      "Initialized GCNNetwork: Layers=3, Hidden=128, Dropout=0.4\n",
      "  ProtT5 MLP initialized: 1024 -> ... -> 128\n",
      "  Combined input dimension for final classifier: 512\n",
      "HybridModel initialization complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Starting training for max 50 epochs (Patience: 10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 01/50 | Tr L:0.6432, A:0.6257 | V L:0.5736, BAcc:0.6966 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 05/50 | Tr L:0.5016, A:0.7584 | V L:0.5510, BAcc:0.7147 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/50 | Tr L:0.3473, A:0.8544 | V L:0.6177, BAcc:0.7120 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 15/50 | Tr L:0.1479, A:0.9438 | V L:0.8627, BAcc:0.7083 | LR:5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Early stopping triggered at epoch 16. Best val loss: 0.5507\n",
      "\n",
      "  Evaluating best model on validation set for Fold 1...\n",
      "  Fold 1 Validation Loss: 0.7951\n",
      "  Fold 1 Validation Accuracy: 0.7233\n",
      "  Fold 1 Validation Balanced Acc: 0.7238\n",
      "  Fold 1 Validation MCC: 0.4473\n",
      "  Fold 1 Validation Sensitivity: 0.7116\n",
      "  Fold 1 Validation Specificity: 0.7359\n",
      "  Fold 1 Validation Confusion Matrix:\n",
      "  [[TN=627   FP=225  ]\n",
      "   [FN=265   TP=654  ]]\n",
      "  Predicting on test set using Fold 1's best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 1 completed in 56.10 seconds =====\n",
      "\n",
      "===== Fold 2/5 =====\n",
      "  Training samples: 7082, Validation samples: 1771\n",
      "Initializing HybridModel (GNN=GCN + ProtT5)\n",
      "  GNN configured NOT to use edge features.\n",
      "Initialized GCNNetwork: Layers=3, Hidden=128, Dropout=0.4\n",
      "  ProtT5 MLP initialized: 1024 -> ... -> 128\n",
      "  Combined input dimension for final classifier: 512\n",
      "HybridModel initialization complete.\n",
      "  Starting training for max 50 epochs (Patience: 10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 01/50 | Tr L:0.6490, A:0.6227 | V L:0.5785, BAcc:0.7002 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 05/50 | Tr L:0.5052, A:0.7544 | V L:0.5469, BAcc:0.7115 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/50 | Tr L:0.3569, A:0.8505 | V L:0.5914, BAcc:0.7122 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 15/50 | Tr L:0.1585, A:0.9404 | V L:0.8781, BAcc:0.7103 | LR:5.0e-04\n",
      "  Early stopping triggered at epoch 15. Best val loss: 0.5469\n",
      "\n",
      "  Evaluating best model on validation set for Fold 2...\n",
      "  Fold 2 Validation Loss: 0.8781\n",
      "  Fold 2 Validation Accuracy: 0.7098\n",
      "  Fold 2 Validation Balanced Acc: 0.7103\n",
      "  Fold 2 Validation MCC: 0.4203\n",
      "  Fold 2 Validation Sensitivity: 0.6964\n",
      "  Fold 2 Validation Specificity: 0.7242\n",
      "  Fold 2 Validation Confusion Matrix:\n",
      "  [[TN=617   FP=235  ]\n",
      "   [FN=279   TP=640  ]]\n",
      "  Predicting on test set using Fold 2's best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 2 completed in 52.20 seconds =====\n",
      "\n",
      "===== Fold 3/5 =====\n",
      "  Training samples: 7082, Validation samples: 1771\n",
      "Initializing HybridModel (GNN=GCN + ProtT5)\n",
      "  GNN configured NOT to use edge features.\n",
      "Initialized GCNNetwork: Layers=3, Hidden=128, Dropout=0.4\n",
      "  ProtT5 MLP initialized: 1024 -> ... -> 128\n",
      "  Combined input dimension for final classifier: 512\n",
      "HybridModel initialization complete.\n",
      "  Starting training for max 50 epochs (Patience: 10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 01/50 | Tr L:0.6394, A:0.6340 | V L:0.5749, BAcc:0.6988 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 05/50 | Tr L:0.4953, A:0.7691 | V L:0.5627, BAcc:0.7061 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/50 | Tr L:0.3607, A:0.8486 | V L:0.6439, BAcc:0.7102 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 15/50 | Tr L:0.1538, A:0.9446 | V L:0.9505, BAcc:0.7029 | LR:5.0e-04\n",
      "  Early stopping triggered at epoch 15. Best val loss: 0.5627\n",
      "\n",
      "  Evaluating best model on validation set for Fold 3...\n",
      "  Fold 3 Validation Loss: 0.9505\n",
      "  Fold 3 Validation Accuracy: 0.7024\n",
      "  Fold 3 Validation Balanced Acc: 0.7029\n",
      "  Fold 3 Validation MCC: 0.4056\n",
      "  Fold 3 Validation Sensitivity: 0.6895\n",
      "  Fold 3 Validation Specificity: 0.7163\n",
      "  Fold 3 Validation Confusion Matrix:\n",
      "  [[TN=611   FP=242  ]\n",
      "   [FN=285   TP=633  ]]\n",
      "  Predicting on test set using Fold 3's best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 3 completed in 53.03 seconds =====\n",
      "\n",
      "===== Fold 4/5 =====\n",
      "  Training samples: 7083, Validation samples: 1770\n",
      "Initializing HybridModel (GNN=GCN + ProtT5)\n",
      "  GNN configured NOT to use edge features.\n",
      "Initialized GCNNetwork: Layers=3, Hidden=128, Dropout=0.4\n",
      "  ProtT5 MLP initialized: 1024 -> ... -> 128\n",
      "  Combined input dimension for final classifier: 512\n",
      "HybridModel initialization complete.\n",
      "  Starting training for max 50 epochs (Patience: 10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 01/50 | Tr L:0.6475, A:0.6187 | V L:0.5683, BAcc:0.7072 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 05/50 | Tr L:0.5054, A:0.7642 | V L:0.5449, BAcc:0.7277 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/50 | Tr L:0.3093, A:0.8793 | V L:0.7057, BAcc:0.7021 | LR:5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Early stopping triggered at epoch 12. Best val loss: 0.5446\n",
      "\n",
      "  Evaluating best model on validation set for Fold 4...\n",
      "  Fold 4 Validation Loss: 0.7378\n",
      "  Fold 4 Validation Accuracy: 0.7203\n",
      "  Fold 4 Validation Balanced Acc: 0.7213\n",
      "  Fold 4 Validation MCC: 0.4426\n",
      "  Fold 4 Validation Sensitivity: 0.6950\n",
      "  Fold 4 Validation Specificity: 0.7477\n",
      "  Fold 4 Validation Confusion Matrix:\n",
      "  [[TN=637   FP=215  ]\n",
      "   [FN=280   TP=638  ]]\n",
      "  Predicting on test set using Fold 4's best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 4 completed in 42.89 seconds =====\n",
      "\n",
      "===== Fold 5/5 =====\n",
      "  Training samples: 7083, Validation samples: 1770\n",
      "Initializing HybridModel (GNN=GCN + ProtT5)\n",
      "  GNN configured NOT to use edge features.\n",
      "Initialized GCNNetwork: Layers=3, Hidden=128, Dropout=0.4\n",
      "  ProtT5 MLP initialized: 1024 -> ... -> 128\n",
      "  Combined input dimension for final classifier: 512\n",
      "HybridModel initialization complete.\n",
      "  Starting training for max 50 epochs (Patience: 10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 01/50 | Tr L:0.6444, A:0.6213 | V L:0.5779, BAcc:0.6988 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 05/50 | Tr L:0.5079, A:0.7572 | V L:0.5506, BAcc:0.7290 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/50 | Tr L:0.3643, A:0.8396 | V L:0.6362, BAcc:0.7243 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 15/50 | Tr L:0.1645, A:0.9372 | V L:0.9097, BAcc:0.7271 | LR:5.0e-04\n",
      "  Early stopping triggered at epoch 15. Best val loss: 0.5506\n",
      "\n",
      "  Evaluating best model on validation set for Fold 5...\n",
      "  Fold 5 Validation Loss: 0.9097\n",
      "  Fold 5 Validation Accuracy: 0.7282\n",
      "  Fold 5 Validation Balanced Acc: 0.7271\n",
      "  Fold 5 Validation MCC: 0.4553\n",
      "  Fold 5 Validation Sensitivity: 0.7582\n",
      "  Fold 5 Validation Specificity: 0.6960\n",
      "  Fold 5 Validation Confusion Matrix:\n",
      "  [[TN=593   FP=259  ]\n",
      "   [FN=222   TP=696  ]]\n",
      "  Predicting on test set using Fold 5's best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 5 completed in 52.24 seconds =====\n",
      "\n",
      "--- Cross-validation Summary for Hybrid GCN+ProtT5 (Edge Feats: False) (Avg +/- Std Dev on Val Folds) ---\n",
      "  Avg Val loss           : 0.8542  0.0774\n",
      "  Avg Val accuracy       : 0.7168  0.0094\n",
      "  Avg Val balanced_acc   : 0.7171  0.0091\n",
      "  Avg Val mcc            : 0.4342  0.0184\n",
      "  Avg Val sensitivity    : 0.7102  0.0251\n",
      "  Avg Val specificity    : 0.7240  0.0176\n",
      "\n",
      "--- Final Test Set Performance for Hybrid GCN+ProtT5 (Edge Feats: False) (Ensemble: Majority Vote) ---\n",
      "Ensemble Test Loss: 0.8542\n",
      "Ensemble Test Accuracy: 0.7095\n",
      "Ensemble Test Balanced Acc: 0.7165\n",
      "Ensemble Test MCC: 0.2605\n",
      "Ensemble Test Sensitivity: 0.7250\n",
      "Ensemble Test Specificity: 0.7080\n",
      "Ensemble Test Confusion Matrix:\n",
      "  [[TN=1768  FP=729  ]\n",
      "   [FN=66    TP=174  ]]\n",
      "\n",
      "--- Evaluation for Hybrid GCN+ProtT5 (Edge Feats: False) completed in 296.11 seconds ---\n",
      "\n",
      "=============== Evaluating: Hybrid PNA+ProtT5 (Edge Feats: False) ===============\n",
      "Preparing graph data (SS Node Features: True, Edge Features: False)...\n",
      "Preparing PyG graph data (GNN+ProtT5 format: Edge Feats=False, SS Node=True) for 8853 aligned samples...\n",
      "  Will attempt to parse features: ['phi', 'psi', 'omega', 'tau', 'chi1', 'chi2', 'chi3', 'chi4', 'sasa', 'ss', 'plDDT', 'distance_map', 'sequence']\n",
      "\n",
      "Graph Preparation Summary:\n",
      "  Created 8853 graphs from 8853 aligned samples.\n",
      "  Skipped 0 rows (ParseErr=0, ConcatErr=0, EdgeErr=0, ValidErr=0, Other=0).\n",
      "  Example graph node feature dimension: 27\n",
      "  Example graph edge feature dimension: N/A\n",
      "  Example ProtT5 embedding dimension: torch.Size([1, 1024])\n",
      "Graph preparation finished in 31.35 seconds.\n",
      "Preparing PyG graph data (GNN+ProtT5 format: Edge Feats=False, SS Node=True) for 2737 aligned samples...\n",
      "  Will attempt to parse features: ['phi', 'psi', 'omega', 'tau', 'chi1', 'chi2', 'chi3', 'chi4', 'sasa', 'ss', 'plDDT', 'distance_map', 'sequence']\n",
      "\n",
      "Graph Preparation Summary:\n",
      "  Created 2737 graphs from 2737 aligned samples.\n",
      "  Skipped 0 rows (ParseErr=0, ConcatErr=0, EdgeErr=0, ValidErr=0, Other=0).\n",
      "  Example graph node feature dimension: 27\n",
      "  Example graph edge feature dimension: N/A\n",
      "  Example ProtT5 embedding dimension: torch.Size([1, 1024])\n",
      "Graph preparation finished in 9.43 seconds.\n",
      "Calculating node degree histogram for PNA (from training graphs)...\n",
      "PNA Max degree: 18\n",
      "Calculated Class weights: {0: 1.0388406477352734, 1: 0.9639590592334495}\n",
      "Feature dimensions used for model init: Nodes=27, Edges=None\n",
      "\n",
      "===== Fold 1/5 =====\n",
      "  Training samples: 7082, Validation samples: 1771\n",
      "Initializing HybridModel (GNN=PNA + ProtT5)\n",
      "  GNN configured NOT to use edge features.\n",
      "Initialized PNANetwork: Layers=3, Hidden=128, Dropout=0.4\n",
      "  ProtT5 MLP initialized: 1024 -> ... -> 128\n",
      "  Combined input dimension for final classifier: 512\n",
      "HybridModel initialization complete.\n",
      "  Starting training for max 50 epochs (Patience: 10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 01/50 | Tr L:0.6469, A:0.6200 | V L:0.5765, BAcc:0.6973 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 05/50 | Tr L:0.5004, A:0.7591 | V L:0.5973, BAcc:0.7125 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/50 | Tr L:0.3459, A:0.8546 | V L:0.6518, BAcc:0.7162 | LR:5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Early stopping triggered at epoch 14. Best val loss: 0.5471\n",
      "\n",
      "  Evaluating best model on validation set for Fold 1...\n",
      "  Fold 1 Validation Loss: 0.8212\n",
      "  Fold 1 Validation Accuracy: 0.7092\n",
      "  Fold 1 Validation Balanced Acc: 0.7100\n",
      "  Fold 1 Validation MCC: 0.4198\n",
      "  Fold 1 Validation Sensitivity: 0.6899\n",
      "  Fold 1 Validation Specificity: 0.7300\n",
      "  Fold 1 Validation Confusion Matrix:\n",
      "  [[TN=622   FP=230  ]\n",
      "   [FN=285   TP=634  ]]\n",
      "  Predicting on test set using Fold 1's best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 1 completed in 134.14 seconds =====\n",
      "\n",
      "===== Fold 2/5 =====\n",
      "  Training samples: 7082, Validation samples: 1771\n",
      "Initializing HybridModel (GNN=PNA + ProtT5)\n",
      "  GNN configured NOT to use edge features.\n",
      "Initialized PNANetwork: Layers=3, Hidden=128, Dropout=0.4\n",
      "  ProtT5 MLP initialized: 1024 -> ... -> 128\n",
      "  Combined input dimension for final classifier: 512\n",
      "HybridModel initialization complete.\n",
      "  Starting training for max 50 epochs (Patience: 10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 01/50 | Tr L:0.6444, A:0.6224 | V L:0.5786, BAcc:0.6974 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 05/50 | Tr L:0.5017, A:0.7616 | V L:0.5850, BAcc:0.7131 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/50 | Tr L:0.3491, A:0.8587 | V L:0.6619, BAcc:0.6965 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 15/50 | Tr L:0.1546, A:0.9451 | V L:0.8493, BAcc:0.7057 | LR:5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Early stopping triggered at epoch 16. Best val loss: 0.5705\n",
      "\n",
      "  Evaluating best model on validation set for Fold 2...\n",
      "  Fold 2 Validation Loss: 0.8561\n",
      "  Fold 2 Validation Accuracy: 0.7115\n",
      "  Fold 2 Validation Balanced Acc: 0.7105\n",
      "  Fold 2 Validation MCC: 0.4216\n",
      "  Fold 2 Validation Sensitivity: 0.7356\n",
      "  Fold 2 Validation Specificity: 0.6854\n",
      "  Fold 2 Validation Confusion Matrix:\n",
      "  [[TN=584   FP=268  ]\n",
      "   [FN=243   TP=676  ]]\n",
      "  Predicting on test set using Fold 2's best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 2 completed in 163.34 seconds =====\n",
      "\n",
      "===== Fold 3/5 =====\n",
      "  Training samples: 7082, Validation samples: 1771\n",
      "Initializing HybridModel (GNN=PNA + ProtT5)\n",
      "  GNN configured NOT to use edge features.\n",
      "Initialized PNANetwork: Layers=3, Hidden=128, Dropout=0.4\n",
      "  ProtT5 MLP initialized: 1024 -> ... -> 128\n",
      "  Combined input dimension for final classifier: 512\n",
      "HybridModel initialization complete.\n",
      "  Starting training for max 50 epochs (Patience: 10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 01/50 | Tr L:0.6412, A:0.6212 | V L:0.5868, BAcc:0.6903 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 05/50 | Tr L:0.5049, A:0.7656 | V L:0.5922, BAcc:0.7063 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/50 | Tr L:0.2941, A:0.8859 | V L:0.7476, BAcc:0.7104 | LR:5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Early stopping triggered at epoch 12. Best val loss: 0.5666\n",
      "\n",
      "  Evaluating best model on validation set for Fold 3...\n",
      "  Fold 3 Validation Loss: 0.8723\n",
      "  Fold 3 Validation Accuracy: 0.6838\n",
      "  Fold 3 Validation Balanced Acc: 0.6889\n",
      "  Fold 3 Validation MCC: 0.3917\n",
      "  Fold 3 Validation Sensitivity: 0.5490\n",
      "  Fold 3 Validation Specificity: 0.8288\n",
      "  Fold 3 Validation Confusion Matrix:\n",
      "  [[TN=707   FP=146  ]\n",
      "   [FN=414   TP=504  ]]\n",
      "  Predicting on test set using Fold 3's best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 3 completed in 133.47 seconds =====\n",
      "\n",
      "===== Fold 4/5 =====\n",
      "  Training samples: 7083, Validation samples: 1770\n",
      "Initializing HybridModel (GNN=PNA + ProtT5)\n",
      "  GNN configured NOT to use edge features.\n",
      "Initialized PNANetwork: Layers=3, Hidden=128, Dropout=0.4\n",
      "  ProtT5 MLP initialized: 1024 -> ... -> 128\n",
      "  Combined input dimension for final classifier: 512\n",
      "HybridModel initialization complete.\n",
      "  Starting training for max 50 epochs (Patience: 10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 01/50 | Tr L:0.6472, A:0.6215 | V L:0.5637, BAcc:0.7056 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 05/50 | Tr L:0.5004, A:0.7582 | V L:0.5645, BAcc:0.7201 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/50 | Tr L:0.2899, A:0.8817 | V L:0.7257, BAcc:0.7157 | LR:5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Early stopping triggered at epoch 12. Best val loss: 0.5544\n",
      "\n",
      "  Evaluating best model on validation set for Fold 4...\n",
      "  Fold 4 Validation Loss: 0.7935\n",
      "  Fold 4 Validation Accuracy: 0.6972\n",
      "  Fold 4 Validation Balanced Acc: 0.6979\n",
      "  Fold 4 Validation MCC: 0.3957\n",
      "  Fold 4 Validation Sensitivity: 0.6776\n",
      "  Fold 4 Validation Specificity: 0.7183\n",
      "  Fold 4 Validation Confusion Matrix:\n",
      "  [[TN=612   FP=240  ]\n",
      "   [FN=296   TP=622  ]]\n",
      "  Predicting on test set using Fold 4's best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 4 completed in 153.79 seconds =====\n",
      "\n",
      "===== Fold 5/5 =====\n",
      "  Training samples: 7083, Validation samples: 1770\n",
      "Initializing HybridModel (GNN=PNA + ProtT5)\n",
      "  GNN configured NOT to use edge features.\n",
      "Initialized PNANetwork: Layers=3, Hidden=128, Dropout=0.4\n",
      "  ProtT5 MLP initialized: 1024 -> ... -> 128\n",
      "  Combined input dimension for final classifier: 512\n",
      "HybridModel initialization complete.\n",
      "  Starting training for max 50 epochs (Patience: 10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 01/50 | Tr L:0.6491, A:0.6205 | V L:0.5914, BAcc:0.6822 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 05/50 | Tr L:0.4985, A:0.7697 | V L:0.6676, BAcc:0.6879 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/50 | Tr L:0.3416, A:0.8614 | V L:0.6734, BAcc:0.7163 | LR:5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='min')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Early stopping triggered at epoch 14. Best val loss: 0.5569\n",
      "\n",
      "  Evaluating best model on validation set for Fold 5...\n",
      "  Fold 5 Validation Loss: 0.8424\n",
      "  Fold 5 Validation Accuracy: 0.7198\n",
      "  Fold 5 Validation Balanced Acc: 0.7210\n",
      "  Fold 5 Validation MCC: 0.4422\n",
      "  Fold 5 Validation Sensitivity: 0.6885\n",
      "  Fold 5 Validation Specificity: 0.7535\n",
      "  Fold 5 Validation Confusion Matrix:\n",
      "  [[TN=642   FP=210  ]\n",
      "   [FN=286   TP=632  ]]\n",
      "  Predicting on test set using Fold 5's best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 5 completed in 183.31 seconds =====\n",
      "\n",
      "--- Cross-validation Summary for Hybrid PNA+ProtT5 (Edge Feats: False) (Avg +/- Std Dev on Val Folds) ---\n",
      "  Avg Val loss           : 0.8371  0.0275\n",
      "  Avg Val accuracy       : 0.7043  0.0125\n",
      "  Avg Val balanced_acc   : 0.7057  0.0111\n",
      "  Avg Val mcc            : 0.4142  0.0185\n",
      "  Avg Val sensitivity    : 0.6681  0.0628\n",
      "  Avg Val specificity    : 0.7432  0.0481\n",
      "\n",
      "--- Final Test Set Performance for Hybrid PNA+ProtT5 (Edge Feats: False) (Ensemble: Majority Vote) ---\n",
      "Ensemble Test Loss: 0.8371\n",
      "Ensemble Test Accuracy: 0.7336\n",
      "Ensemble Test Balanced Acc: 0.7128\n",
      "Ensemble Test MCC: 0.2629\n",
      "Ensemble Test Sensitivity: 0.6875\n",
      "Ensemble Test Specificity: 0.7381\n",
      "Ensemble Test Confusion Matrix:\n",
      "  [[TN=1843  FP=654  ]\n",
      "   [FN=75    TP=165  ]]\n",
      "\n",
      "--- Evaluation for Hybrid PNA+ProtT5 (Edge Feats: False) completed in 809.51 seconds ---\n",
      "\n",
      "=============== Evaluating: Hybrid GATV2+ProtT5 (Edge Feats: False) ===============\n",
      "Preparing graph data (SS Node Features: True, Edge Features: False)...\n",
      "Preparing PyG graph data (GNN+ProtT5 format: Edge Feats=False, SS Node=True) for 8853 aligned samples...\n",
      "  Will attempt to parse features: ['phi', 'psi', 'omega', 'tau', 'chi1', 'chi2', 'chi3', 'chi4', 'sasa', 'ss', 'plDDT', 'distance_map', 'sequence']\n",
      "\n",
      "Graph Preparation Summary:\n",
      "  Created 8853 graphs from 8853 aligned samples.\n",
      "  Skipped 0 rows (ParseErr=0, ConcatErr=0, EdgeErr=0, ValidErr=0, Other=0).\n",
      "  Example graph node feature dimension: 27\n",
      "  Example graph edge feature dimension: N/A\n",
      "  Example ProtT5 embedding dimension: torch.Size([1, 1024])\n",
      "Graph preparation finished in 33.98 seconds.\n",
      "Preparing PyG graph data (GNN+ProtT5 format: Edge Feats=False, SS Node=True) for 2737 aligned samples...\n",
      "  Will attempt to parse features: ['phi', 'psi', 'omega', 'tau', 'chi1', 'chi2', 'chi3', 'chi4', 'sasa', 'ss', 'plDDT', 'distance_map', 'sequence']\n",
      "\n",
      "Graph Preparation Summary:\n",
      "  Created 2737 graphs from 2737 aligned samples.\n",
      "  Skipped 0 rows (ParseErr=0, ConcatErr=0, EdgeErr=0, ValidErr=0, Other=0).\n",
      "  Example graph node feature dimension: 27\n",
      "  Example graph edge feature dimension: N/A\n",
      "  Example ProtT5 embedding dimension: torch.Size([1, 1024])\n",
      "Graph preparation finished in 10.40 seconds.\n",
      "Calculated Class weights: {0: 1.0388406477352734, 1: 0.9639590592334495}\n",
      "Feature dimensions used for model init: Nodes=27, Edges=None\n",
      "\n",
      "===== Fold 1/5 =====\n",
      "  Training samples: 7082, Validation samples: 1771\n",
      "Initializing HybridModel (GNN=GATV2 + ProtT5)\n",
      "  GNN configured NOT to use edge features.\n",
      "Initialized GATv2Network: Layers=3, Hidden=128, Heads=4, Dropout=0.4, EdgeDim=None\n",
      "  ProtT5 MLP initialized: 1024 -> ... -> 128\n",
      "  Combined input dimension for final classifier: 512\n",
      "HybridModel initialization complete.\n",
      "  Starting training for max 50 epochs (Patience: 10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 01/50 | Tr L:0.6433, A:0.6226 | V L:0.6539, BAcc:0.6545 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 05/50 | Tr L:0.5077, A:0.7591 | V L:0.5440, BAcc:0.7232 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/50 | Tr L:0.3745, A:0.8379 | V L:0.6152, BAcc:0.7185 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 15/50 | Tr L:0.1730, A:0.9343 | V L:0.7986, BAcc:0.7228 | LR:5.0e-04\n",
      "  Early stopping triggered at epoch 15. Best val loss: 0.5440\n",
      "\n",
      "  Evaluating best model on validation set for Fold 1...\n",
      "  Fold 1 Validation Loss: 0.7986\n",
      "  Fold 1 Validation Accuracy: 0.7233\n",
      "  Fold 1 Validation Balanced Acc: 0.7228\n",
      "  Fold 1 Validation MCC: 0.4458\n",
      "  Fold 1 Validation Sensitivity: 0.7356\n",
      "  Fold 1 Validation Specificity: 0.7101\n",
      "  Fold 1 Validation Confusion Matrix:\n",
      "  [[TN=605   FP=247  ]\n",
      "   [FN=243   TP=676  ]]\n",
      "  Predicting on test set using Fold 1's best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 1 completed in 120.80 seconds =====\n",
      "\n",
      "===== Fold 2/5 =====\n",
      "  Training samples: 7082, Validation samples: 1771\n",
      "Initializing HybridModel (GNN=GATV2 + ProtT5)\n",
      "  GNN configured NOT to use edge features.\n",
      "Initialized GATv2Network: Layers=3, Hidden=128, Heads=4, Dropout=0.4, EdgeDim=None\n",
      "  ProtT5 MLP initialized: 1024 -> ... -> 128\n",
      "  Combined input dimension for final classifier: 512\n",
      "HybridModel initialization complete.\n",
      "  Starting training for max 50 epochs (Patience: 10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 01/50 | Tr L:0.6479, A:0.6209 | V L:0.5737, BAcc:0.6932 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 05/50 | Tr L:0.5028, A:0.7581 | V L:0.5576, BAcc:0.7131 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/50 | Tr L:0.3594, A:0.8499 | V L:0.6098, BAcc:0.7131 | LR:5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Early stopping triggered at epoch 14. Best val loss: 0.5482\n",
      "\n",
      "  Evaluating best model on validation set for Fold 2...\n",
      "  Fold 2 Validation Loss: 0.7736\n",
      "  Fold 2 Validation Accuracy: 0.7002\n",
      "  Fold 2 Validation Balanced Acc: 0.7011\n",
      "  Fold 2 Validation MCC: 0.4021\n",
      "  Fold 2 Validation Sensitivity: 0.6768\n",
      "  Fold 2 Validation Specificity: 0.7254\n",
      "  Fold 2 Validation Confusion Matrix:\n",
      "  [[TN=618   FP=234  ]\n",
      "   [FN=297   TP=622  ]]\n",
      "  Predicting on test set using Fold 2's best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 2 completed in 101.63 seconds =====\n",
      "\n",
      "===== Fold 3/5 =====\n",
      "  Training samples: 7082, Validation samples: 1771\n",
      "Initializing HybridModel (GNN=GATV2 + ProtT5)\n",
      "  GNN configured NOT to use edge features.\n",
      "Initialized GATv2Network: Layers=3, Hidden=128, Heads=4, Dropout=0.4, EdgeDim=None\n",
      "  ProtT5 MLP initialized: 1024 -> ... -> 128\n",
      "  Combined input dimension for final classifier: 512\n",
      "HybridModel initialization complete.\n",
      "  Starting training for max 50 epochs (Patience: 10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 01/50 | Tr L:0.6408, A:0.6243 | V L:0.5807, BAcc:0.6869 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 05/50 | Tr L:0.4935, A:0.7676 | V L:0.5759, BAcc:0.7119 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/50 | Tr L:0.3066, A:0.8763 | V L:0.6919, BAcc:0.7064 | LR:5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Early stopping triggered at epoch 12. Best val loss: 0.5633\n",
      "\n",
      "  Evaluating best model on validation set for Fold 3...\n",
      "  Fold 3 Validation Loss: 0.8026\n",
      "  Fold 3 Validation Accuracy: 0.7024\n",
      "  Fold 3 Validation Balanced Acc: 0.7019\n",
      "  Fold 3 Validation MCC: 0.4039\n",
      "  Fold 3 Validation Sensitivity: 0.7157\n",
      "  Fold 3 Validation Specificity: 0.6882\n",
      "  Fold 3 Validation Confusion Matrix:\n",
      "  [[TN=587   FP=266  ]\n",
      "   [FN=261   TP=657  ]]\n",
      "  Predicting on test set using Fold 3's best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 3 completed in 87.35 seconds =====\n",
      "\n",
      "===== Fold 4/5 =====\n",
      "  Training samples: 7083, Validation samples: 1770\n",
      "Initializing HybridModel (GNN=GATV2 + ProtT5)\n",
      "  GNN configured NOT to use edge features.\n",
      "Initialized GATv2Network: Layers=3, Hidden=128, Heads=4, Dropout=0.4, EdgeDim=None\n",
      "  ProtT5 MLP initialized: 1024 -> ... -> 128\n",
      "  Combined input dimension for final classifier: 512\n",
      "HybridModel initialization complete.\n",
      "  Starting training for max 50 epochs (Patience: 10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 01/50 | Tr L:0.6429, A:0.6264 | V L:0.5723, BAcc:0.7037 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 05/50 | Tr L:0.5041, A:0.7597 | V L:0.5375, BAcc:0.7279 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/50 | Tr L:0.3456, A:0.8566 | V L:0.6500, BAcc:0.7094 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 15/50 | Tr L:0.1529, A:0.9445 | V L:0.8900, BAcc:0.7066 | LR:5.0e-04\n",
      "  Early stopping triggered at epoch 15. Best val loss: 0.5375\n",
      "\n",
      "  Evaluating best model on validation set for Fold 4...\n",
      "  Fold 4 Validation Loss: 0.8900\n",
      "  Fold 4 Validation Accuracy: 0.7062\n",
      "  Fold 4 Validation Balanced Acc: 0.7066\n",
      "  Fold 4 Validation MCC: 0.4130\n",
      "  Fold 4 Validation Sensitivity: 0.6950\n",
      "  Fold 4 Validation Specificity: 0.7183\n",
      "  Fold 4 Validation Confusion Matrix:\n",
      "  [[TN=612   FP=240  ]\n",
      "   [FN=280   TP=638  ]]\n",
      "  Predicting on test set using Fold 4's best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 4 completed in 106.97 seconds =====\n",
      "\n",
      "===== Fold 5/5 =====\n",
      "  Training samples: 7083, Validation samples: 1770\n",
      "Initializing HybridModel (GNN=GATV2 + ProtT5)\n",
      "  GNN configured NOT to use edge features.\n",
      "Initialized GATv2Network: Layers=3, Hidden=128, Heads=4, Dropout=0.4, EdgeDim=None\n",
      "  ProtT5 MLP initialized: 1024 -> ... -> 128\n",
      "  Combined input dimension for final classifier: 512\n",
      "HybridModel initialization complete.\n",
      "  Starting training for max 50 epochs (Patience: 10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 01/50 | Tr L:0.6472, A:0.6180 | V L:0.5654, BAcc:0.6962 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 05/50 | Tr L:0.5033, A:0.7615 | V L:0.5513, BAcc:0.7152 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/50 | Tr L:0.3640, A:0.8437 | V L:0.6455, BAcc:0.7254 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 15/50 | Tr L:0.1709, A:0.9384 | V L:0.8487, BAcc:0.7234 | LR:5.0e-04\n",
      "  Early stopping triggered at epoch 15. Best val loss: 0.5513\n",
      "\n",
      "  Evaluating best model on validation set for Fold 5...\n",
      "  Fold 5 Validation Loss: 0.8487\n",
      "  Fold 5 Validation Accuracy: 0.7226\n",
      "  Fold 5 Validation Balanced Acc: 0.7234\n",
      "  Fold 5 Validation MCC: 0.4466\n",
      "  Fold 5 Validation Sensitivity: 0.7026\n",
      "  Fold 5 Validation Specificity: 0.7441\n",
      "  Fold 5 Validation Confusion Matrix:\n",
      "  [[TN=634   FP=218  ]\n",
      "   [FN=273   TP=645  ]]\n",
      "  Predicting on test set using Fold 5's best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 5 completed in 92.66 seconds =====\n",
      "\n",
      "--- Cross-validation Summary for Hybrid GATV2+ProtT5 (Edge Feats: False) (Avg +/- Std Dev on Val Folds) ---\n",
      "  Avg Val loss           : 0.8227  0.0415\n",
      "  Avg Val accuracy       : 0.7109  0.0100\n",
      "  Avg Val balanced_acc   : 0.7112  0.0099\n",
      "  Avg Val mcc            : 0.4223  0.0199\n",
      "  Avg Val sensitivity    : 0.7051  0.0197\n",
      "  Avg Val specificity    : 0.7172  0.0184\n",
      "\n",
      "--- Final Test Set Performance for Hybrid GATV2+ProtT5 (Edge Feats: False) (Ensemble: Majority Vote) ---\n",
      "Ensemble Test Loss: 0.8227\n",
      "Ensemble Test Accuracy: 0.7033\n",
      "Ensemble Test Balanced Acc: 0.7169\n",
      "Ensemble Test MCC: 0.2594\n",
      "Ensemble Test Sensitivity: 0.7333\n",
      "Ensemble Test Specificity: 0.7004\n",
      "Ensemble Test Confusion Matrix:\n",
      "  [[TN=1749  FP=748  ]\n",
      "   [FN=64    TP=176  ]]\n",
      "\n",
      "--- Evaluation for Hybrid GATV2+ProtT5 (Edge Feats: False) completed in 553.82 seconds ---\n",
      "\n",
      "=============== Evaluating: Hybrid GATV2+ProtT5 (Edge Feats: True) ===============\n",
      "Preparing graph data (SS Node Features: True, Edge Features: True)...\n",
      "Preparing PyG graph data (GNN+ProtT5 format: Edge Feats=True, SS Node=True) for 8853 aligned samples...\n",
      "  Will attempt to parse features: ['phi', 'psi', 'omega', 'tau', 'chi1', 'chi2', 'chi3', 'chi4', 'sasa', 'ss', 'plDDT', 'distance_map', 'sequence']\n",
      "\n",
      "Graph Preparation Summary:\n",
      "  Created 8853 graphs from 8853 aligned samples.\n",
      "  Skipped 0 rows (ParseErr=0, ConcatErr=0, EdgeErr=0, ValidErr=0, Other=0).\n",
      "  Example graph node feature dimension: 27\n",
      "  Example graph edge feature dimension: 17\n",
      "  Example ProtT5 embedding dimension: torch.Size([1, 1024])\n",
      "Graph preparation finished in 113.12 seconds.\n",
      "Preparing PyG graph data (GNN+ProtT5 format: Edge Feats=True, SS Node=True) for 2737 aligned samples...\n",
      "  Will attempt to parse features: ['phi', 'psi', 'omega', 'tau', 'chi1', 'chi2', 'chi3', 'chi4', 'sasa', 'ss', 'plDDT', 'distance_map', 'sequence']\n",
      "\n",
      "Graph Preparation Summary:\n",
      "  Created 2737 graphs from 2737 aligned samples.\n",
      "  Skipped 0 rows (ParseErr=0, ConcatErr=0, EdgeErr=0, ValidErr=0, Other=0).\n",
      "  Example graph node feature dimension: 27\n",
      "  Example graph edge feature dimension: 17\n",
      "  Example ProtT5 embedding dimension: torch.Size([1, 1024])\n",
      "Graph preparation finished in 34.33 seconds.\n",
      "Calculated Class weights: {0: 1.0388406477352734, 1: 0.9639590592334495}\n",
      "Feature dimensions used for model init: Nodes=27, Edges=17\n",
      "\n",
      "===== Fold 1/5 =====\n",
      "  Training samples: 7082, Validation samples: 1771\n",
      "Initializing HybridModel (GNN=GATV2 + ProtT5)\n",
      "  GNN configured to use edge features (dim=17)\n",
      "Initialized GATv2Network: Layers=3, Hidden=128, Heads=4, Dropout=0.4, EdgeDim=17\n",
      "  ProtT5 MLP initialized: 1024 -> ... -> 128\n",
      "  Combined input dimension for final classifier: 512\n",
      "HybridModel initialization complete.\n",
      "  Starting training for max 50 epochs (Patience: 10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 01/50 | Tr L:0.6447, A:0.6221 | V L:0.6759, BAcc:0.5925 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 05/50 | Tr L:0.5004, A:0.7635 | V L:0.5721, BAcc:0.7085 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/50 | Tr L:0.3382, A:0.8642 | V L:0.8276, BAcc:0.6763 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 15/50 | Tr L:0.1651, A:0.9373 | V L:1.0332, BAcc:0.6933 | LR:5.0e-04\n",
      "  Early stopping triggered at epoch 15. Best val loss: 0.5721\n",
      "\n",
      "  Evaluating best model on validation set for Fold 1...\n",
      "  Fold 1 Validation Loss: 1.0332\n",
      "  Fold 1 Validation Accuracy: 0.6872\n",
      "  Fold 1 Validation Balanced Acc: 0.6933\n",
      "  Fold 1 Validation MCC: 0.4060\n",
      "  Fold 1 Validation Sensitivity: 0.5321\n",
      "  Fold 1 Validation Specificity: 0.8545\n",
      "  Fold 1 Validation Confusion Matrix:\n",
      "  [[TN=728   FP=124  ]\n",
      "   [FN=430   TP=489  ]]\n",
      "  Predicting on test set using Fold 1's best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 1 completed in 132.02 seconds =====\n",
      "\n",
      "===== Fold 2/5 =====\n",
      "  Training samples: 7082, Validation samples: 1771\n",
      "Initializing HybridModel (GNN=GATV2 + ProtT5)\n",
      "  GNN configured to use edge features (dim=17)\n",
      "Initialized GATv2Network: Layers=3, Hidden=128, Heads=4, Dropout=0.4, EdgeDim=17\n",
      "  ProtT5 MLP initialized: 1024 -> ... -> 128\n",
      "  Combined input dimension for final classifier: 512\n",
      "HybridModel initialization complete.\n",
      "  Starting training for max 50 epochs (Patience: 10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 01/50 | Tr L:0.6437, A:0.6241 | V L:0.7450, BAcc:0.5911 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 05/50 | Tr L:0.5021, A:0.7645 | V L:0.6404, BAcc:0.6938 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/50 | Tr L:0.3038, A:0.8810 | V L:0.7410, BAcc:0.6769 | LR:5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Early stopping triggered at epoch 12. Best val loss: 0.6314\n",
      "\n",
      "  Evaluating best model on validation set for Fold 2...\n",
      "  Fold 2 Validation Loss: 0.7895\n",
      "  Fold 2 Validation Accuracy: 0.7041\n",
      "  Fold 2 Validation Balanced Acc: 0.7072\n",
      "  Fold 2 Validation MCC: 0.4185\n",
      "  Fold 2 Validation Sensitivity: 0.6268\n",
      "  Fold 2 Validation Specificity: 0.7876\n",
      "  Fold 2 Validation Confusion Matrix:\n",
      "  [[TN=671   FP=181  ]\n",
      "   [FN=343   TP=576  ]]\n",
      "  Predicting on test set using Fold 2's best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 2 completed in 104.21 seconds =====\n",
      "\n",
      "===== Fold 3/5 =====\n",
      "  Training samples: 7082, Validation samples: 1771\n",
      "Initializing HybridModel (GNN=GATV2 + ProtT5)\n",
      "  GNN configured to use edge features (dim=17)\n",
      "Initialized GATv2Network: Layers=3, Hidden=128, Heads=4, Dropout=0.4, EdgeDim=17\n",
      "  ProtT5 MLP initialized: 1024 -> ... -> 128\n",
      "  Combined input dimension for final classifier: 512\n",
      "HybridModel initialization complete.\n",
      "  Starting training for max 50 epochs (Patience: 10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 01/50 | Tr L:0.6339, A:0.6324 | V L:0.6508, BAcc:0.6413 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 05/50 | Tr L:0.5014, A:0.7646 | V L:0.5732, BAcc:0.7152 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/50 | Tr L:0.3616, A:0.8522 | V L:0.7010, BAcc:0.6845 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 15/50 | Tr L:0.1640, A:0.9380 | V L:0.8534, BAcc:0.7038 | LR:5.0e-04\n",
      "  Early stopping triggered at epoch 15. Best val loss: 0.5732\n",
      "\n",
      "  Evaluating best model on validation set for Fold 3...\n",
      "  Fold 3 Validation Loss: 0.8534\n",
      "  Fold 3 Validation Accuracy: 0.7030\n",
      "  Fold 3 Validation Balanced Acc: 0.7038\n",
      "  Fold 3 Validation MCC: 0.4074\n",
      "  Fold 3 Validation Sensitivity: 0.6830\n",
      "  Fold 3 Validation Specificity: 0.7245\n",
      "  Fold 3 Validation Confusion Matrix:\n",
      "  [[TN=618   FP=235  ]\n",
      "   [FN=291   TP=627  ]]\n",
      "  Predicting on test set using Fold 3's best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 3 completed in 125.10 seconds =====\n",
      "\n",
      "===== Fold 4/5 =====\n",
      "  Training samples: 7083, Validation samples: 1770\n",
      "Initializing HybridModel (GNN=GATV2 + ProtT5)\n",
      "  GNN configured to use edge features (dim=17)\n",
      "Initialized GATv2Network: Layers=3, Hidden=128, Heads=4, Dropout=0.4, EdgeDim=17\n",
      "  ProtT5 MLP initialized: 1024 -> ... -> 128\n",
      "  Combined input dimension for final classifier: 512\n",
      "HybridModel initialization complete.\n",
      "  Starting training for max 50 epochs (Patience: 10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 01/50 | Tr L:0.6443, A:0.6266 | V L:0.6121, BAcc:0.6689 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 05/50 | Tr L:0.4953, A:0.7663 | V L:0.5888, BAcc:0.6960 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/50 | Tr L:0.3403, A:0.8611 | V L:0.6842, BAcc:0.6817 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 15/50 | Tr L:0.1523, A:0.9458 | V L:0.7554, BAcc:0.7244 | LR:5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Early stopping triggered at epoch 17. Best val loss: 0.5762\n",
      "\n",
      "  Evaluating best model on validation set for Fold 4...\n",
      "  Fold 4 Validation Loss: 0.8291\n",
      "  Fold 4 Validation Accuracy: 0.7130\n",
      "  Fold 4 Validation Balanced Acc: 0.7136\n",
      "  Fold 4 Validation MCC: 0.4269\n",
      "  Fold 4 Validation Sensitivity: 0.6983\n",
      "  Fold 4 Validation Specificity: 0.7289\n",
      "  Fold 4 Validation Confusion Matrix:\n",
      "  [[TN=621   FP=231  ]\n",
      "   [FN=277   TP=641  ]]\n",
      "  Predicting on test set using Fold 4's best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 4 completed in 117.49 seconds =====\n",
      "\n",
      "===== Fold 5/5 =====\n",
      "  Training samples: 7083, Validation samples: 1770\n",
      "Initializing HybridModel (GNN=GATV2 + ProtT5)\n",
      "  GNN configured to use edge features (dim=17)\n",
      "Initialized GATv2Network: Layers=3, Hidden=128, Heads=4, Dropout=0.4, EdgeDim=17\n",
      "  ProtT5 MLP initialized: 1024 -> ... -> 128\n",
      "  Combined input dimension for final classifier: 512\n",
      "HybridModel initialization complete.\n",
      "  Starting training for max 50 epochs (Patience: 10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 01/50 | Tr L:0.6447, A:0.6274 | V L:0.7398, BAcc:0.5837 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 05/50 | Tr L:0.5052, A:0.7666 | V L:0.6633, BAcc:0.6776 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/50 | Tr L:0.3182, A:0.8722 | V L:0.7840, BAcc:0.6944 | LR:5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Early stopping triggered at epoch 12. Best val loss: 0.5759\n",
      "\n",
      "  Evaluating best model on validation set for Fold 5...\n",
      "  Fold 5 Validation Loss: 0.7226\n",
      "  Fold 5 Validation Accuracy: 0.7164\n",
      "  Fold 5 Validation Balanced Acc: 0.7165\n",
      "  Fold 5 Validation MCC: 0.4326\n",
      "  Fold 5 Validation Sensitivity: 0.7146\n",
      "  Fold 5 Validation Specificity: 0.7183\n",
      "  Fold 5 Validation Confusion Matrix:\n",
      "  [[TN=612   FP=240  ]\n",
      "   [FN=262   TP=656  ]]\n",
      "  Predicting on test set using Fold 5's best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 5 completed in 80.41 seconds =====\n",
      "\n",
      "--- Cross-validation Summary for Hybrid GATV2+ProtT5 (Edge Feats: True) (Avg +/- Std Dev on Val Folds) ---\n",
      "  Avg Val loss           : 0.8456  0.1037\n",
      "  Avg Val accuracy       : 0.7047  0.0102\n",
      "  Avg Val balanced_acc   : 0.7068  0.0081\n",
      "  Avg Val mcc            : 0.4183  0.0105\n",
      "  Avg Val sensitivity    : 0.6509  0.0664\n",
      "  Avg Val specificity    : 0.7627  0.0522\n",
      "\n",
      "--- Final Test Set Performance for Hybrid GATV2+ProtT5 (Edge Feats: True) (Ensemble: Majority Vote) ---\n",
      "Ensemble Test Loss: 0.8456\n",
      "Ensemble Test Accuracy: 0.7391\n",
      "Ensemble Test Balanced Acc: 0.7007\n",
      "Ensemble Test MCC: 0.2508\n",
      "Ensemble Test Sensitivity: 0.6542\n",
      "Ensemble Test Specificity: 0.7473\n",
      "Ensemble Test Confusion Matrix:\n",
      "  [[TN=1866  FP=631  ]\n",
      "   [FN=83    TP=157  ]]\n",
      "\n",
      "--- Evaluation for Hybrid GATV2+ProtT5 (Edge Feats: True) completed in 706.71 seconds ---\n",
      "\n",
      "=============== Evaluating: Hybrid GINE+ProtT5 (Edge Feats: True) ===============\n",
      "Preparing graph data (SS Node Features: True, Edge Features: True)...\n",
      "Preparing PyG graph data (GNN+ProtT5 format: Edge Feats=True, SS Node=True) for 8853 aligned samples...\n",
      "  Will attempt to parse features: ['phi', 'psi', 'omega', 'tau', 'chi1', 'chi2', 'chi3', 'chi4', 'sasa', 'ss', 'plDDT', 'distance_map', 'sequence']\n",
      "\n",
      "Graph Preparation Summary:\n",
      "  Created 8853 graphs from 8853 aligned samples.\n",
      "  Skipped 0 rows (ParseErr=0, ConcatErr=0, EdgeErr=0, ValidErr=0, Other=0).\n",
      "  Example graph node feature dimension: 27\n",
      "  Example graph edge feature dimension: 17\n",
      "  Example ProtT5 embedding dimension: torch.Size([1, 1024])\n",
      "Graph preparation finished in 112.12 seconds.\n",
      "Preparing PyG graph data (GNN+ProtT5 format: Edge Feats=True, SS Node=True) for 2737 aligned samples...\n",
      "  Will attempt to parse features: ['phi', 'psi', 'omega', 'tau', 'chi1', 'chi2', 'chi3', 'chi4', 'sasa', 'ss', 'plDDT', 'distance_map', 'sequence']\n",
      "\n",
      "Graph Preparation Summary:\n",
      "  Created 2737 graphs from 2737 aligned samples.\n",
      "  Skipped 0 rows (ParseErr=0, ConcatErr=0, EdgeErr=0, ValidErr=0, Other=0).\n",
      "  Example graph node feature dimension: 27\n",
      "  Example graph edge feature dimension: 17\n",
      "  Example ProtT5 embedding dimension: torch.Size([1, 1024])\n",
      "Graph preparation finished in 33.45 seconds.\n",
      "Calculated Class weights: {0: 1.0388406477352734, 1: 0.9639590592334495}\n",
      "Feature dimensions used for model init: Nodes=27, Edges=17\n",
      "\n",
      "===== Fold 1/5 =====\n",
      "  Training samples: 7082, Validation samples: 1771\n",
      "Initializing HybridModel (GNN=GINE + ProtT5)\n",
      "  GNN configured to use edge features (dim=17)\n",
      "Initialized GINENetwork: Layers=3, Hidden=128, Dropout=0.4, EdgeDim=17\n",
      "  ProtT5 MLP initialized: 1024 -> ... -> 128\n",
      "  Combined input dimension for final classifier: 512\n",
      "HybridModel initialization complete.\n",
      "  Starting training for max 50 epochs (Patience: 10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 01/50 | Tr L:0.6447, A:0.6278 | V L:0.6213, BAcc:0.6519 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 05/50 | Tr L:0.5115, A:0.7608 | V L:0.5483, BAcc:0.7211 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/50 | Tr L:0.3677, A:0.8421 | V L:0.6457, BAcc:0.6978 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 15/50 | Tr L:0.1640, A:0.9396 | V L:0.9239, BAcc:0.7174 | LR:5.0e-04\n",
      "  Early stopping triggered at epoch 15. Best val loss: 0.5483\n",
      "\n",
      "  Evaluating best model on validation set for Fold 1...\n",
      "  Fold 1 Validation Loss: 0.9239\n",
      "  Fold 1 Validation Accuracy: 0.7137\n",
      "  Fold 1 Validation Balanced Acc: 0.7174\n",
      "  Fold 1 Validation MCC: 0.4413\n",
      "  Fold 1 Validation Sensitivity: 0.6213\n",
      "  Fold 1 Validation Specificity: 0.8134\n",
      "  Fold 1 Validation Confusion Matrix:\n",
      "  [[TN=693   FP=159  ]\n",
      "   [FN=348   TP=571  ]]\n",
      "  Predicting on test set using Fold 1's best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 1 completed in 78.12 seconds =====\n",
      "\n",
      "===== Fold 2/5 =====\n",
      "  Training samples: 7082, Validation samples: 1771\n",
      "Initializing HybridModel (GNN=GINE + ProtT5)\n",
      "  GNN configured to use edge features (dim=17)\n",
      "Initialized GINENetwork: Layers=3, Hidden=128, Dropout=0.4, EdgeDim=17\n",
      "  ProtT5 MLP initialized: 1024 -> ... -> 128\n",
      "  Combined input dimension for final classifier: 512\n",
      "HybridModel initialization complete.\n",
      "  Starting training for max 50 epochs (Patience: 10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 01/50 | Tr L:0.6457, A:0.6223 | V L:0.5841, BAcc:0.6998 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 05/50 | Tr L:0.5066, A:0.7518 | V L:0.5697, BAcc:0.7055 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/50 | Tr L:0.3641, A:0.8462 | V L:0.6232, BAcc:0.7114 | LR:5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Early stopping triggered at epoch 14. Best val loss: 0.5522\n",
      "\n",
      "  Evaluating best model on validation set for Fold 2...\n",
      "  Fold 2 Validation Loss: 0.8367\n",
      "  Fold 2 Validation Accuracy: 0.7103\n",
      "  Fold 2 Validation Balanced Acc: 0.7100\n",
      "  Fold 2 Validation MCC: 0.4199\n",
      "  Fold 2 Validation Sensitivity: 0.7193\n",
      "  Fold 2 Validation Specificity: 0.7007\n",
      "  Fold 2 Validation Confusion Matrix:\n",
      "  [[TN=597   FP=255  ]\n",
      "   [FN=258   TP=661  ]]\n",
      "  Predicting on test set using Fold 2's best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 2 completed in 73.12 seconds =====\n",
      "\n",
      "===== Fold 3/5 =====\n",
      "  Training samples: 7082, Validation samples: 1771\n",
      "Initializing HybridModel (GNN=GINE + ProtT5)\n",
      "  GNN configured to use edge features (dim=17)\n",
      "Initialized GINENetwork: Layers=3, Hidden=128, Dropout=0.4, EdgeDim=17\n",
      "  ProtT5 MLP initialized: 1024 -> ... -> 128\n",
      "  Combined input dimension for final classifier: 512\n",
      "HybridModel initialization complete.\n",
      "  Starting training for max 50 epochs (Patience: 10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 01/50 | Tr L:0.6421, A:0.6228 | V L:0.5846, BAcc:0.6813 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 05/50 | Tr L:0.5035, A:0.7592 | V L:0.5829, BAcc:0.7020 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/50 | Tr L:0.3625, A:0.8482 | V L:0.6815, BAcc:0.6877 | LR:5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Early stopping triggered at epoch 14. Best val loss: 0.5703\n",
      "\n",
      "  Evaluating best model on validation set for Fold 3...\n",
      "  Fold 3 Validation Loss: 0.8198\n",
      "  Fold 3 Validation Accuracy: 0.7047\n",
      "  Fold 3 Validation Balanced Acc: 0.7053\n",
      "  Fold 3 Validation MCC: 0.4103\n",
      "  Fold 3 Validation Sensitivity: 0.6895\n",
      "  Fold 3 Validation Specificity: 0.7210\n",
      "  Fold 3 Validation Confusion Matrix:\n",
      "  [[TN=615   FP=238  ]\n",
      "   [FN=285   TP=633  ]]\n",
      "  Predicting on test set using Fold 3's best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 3 completed in 71.17 seconds =====\n",
      "\n",
      "===== Fold 4/5 =====\n",
      "  Training samples: 7083, Validation samples: 1770\n",
      "Initializing HybridModel (GNN=GINE + ProtT5)\n",
      "  GNN configured to use edge features (dim=17)\n",
      "Initialized GINENetwork: Layers=3, Hidden=128, Dropout=0.4, EdgeDim=17\n",
      "  ProtT5 MLP initialized: 1024 -> ... -> 128\n",
      "  Combined input dimension for final classifier: 512\n",
      "HybridModel initialization complete.\n",
      "  Starting training for max 50 epochs (Patience: 10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 01/50 | Tr L:0.6441, A:0.6322 | V L:0.5773, BAcc:0.7092 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 05/50 | Tr L:0.5074, A:0.7587 | V L:0.5762, BAcc:0.7124 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/50 | Tr L:0.3090, A:0.8753 | V L:0.7069, BAcc:0.7090 | LR:5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Early stopping triggered at epoch 13. Best val loss: 0.5547\n",
      "\n",
      "  Evaluating best model on validation set for Fold 4...\n",
      "  Fold 4 Validation Loss: 0.8251\n",
      "  Fold 4 Validation Accuracy: 0.7034\n",
      "  Fold 4 Validation Balanced Acc: 0.7040\n",
      "  Fold 4 Validation MCC: 0.4078\n",
      "  Fold 4 Validation Sensitivity: 0.6874\n",
      "  Fold 4 Validation Specificity: 0.7207\n",
      "  Fold 4 Validation Confusion Matrix:\n",
      "  [[TN=614   FP=238  ]\n",
      "   [FN=287   TP=631  ]]\n",
      "  Predicting on test set using Fold 4's best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 4 completed in 67.63 seconds =====\n",
      "\n",
      "===== Fold 5/5 =====\n",
      "  Training samples: 7083, Validation samples: 1770\n",
      "Initializing HybridModel (GNN=GINE + ProtT5)\n",
      "  GNN configured to use edge features (dim=17)\n",
      "Initialized GINENetwork: Layers=3, Hidden=128, Dropout=0.4, EdgeDim=17\n",
      "  ProtT5 MLP initialized: 1024 -> ... -> 128\n",
      "  Combined input dimension for final classifier: 512\n",
      "HybridModel initialization complete.\n",
      "  Starting training for max 50 epochs (Patience: 10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 01/50 | Tr L:0.6444, A:0.6295 | V L:0.5942, BAcc:0.6908 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 05/50 | Tr L:0.5111, A:0.7552 | V L:0.5645, BAcc:0.7281 | LR:1.0e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/50 | Tr L:0.3331, A:0.8609 | V L:0.7449, BAcc:0.7091 | LR:5.0e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n",
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Early stopping triggered at epoch 13. Best val loss: 0.5614\n",
      "\n",
      "  Evaluating best model on validation set for Fold 5...\n",
      "  Fold 5 Validation Loss: 0.8446\n",
      "  Fold 5 Validation Accuracy: 0.7023\n",
      "  Fold 5 Validation Balanced Acc: 0.7055\n",
      "  Fold 5 Validation MCC: 0.4157\n",
      "  Fold 5 Validation Sensitivity: 0.6198\n",
      "  Fold 5 Validation Specificity: 0.7911\n",
      "  Fold 5 Validation Confusion Matrix:\n",
      "  [[TN=674   FP=178  ]\n",
      "   [FN=349   TP=569  ]]\n",
      "  Predicting on test set using Fold 5's best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/miniconda3/envs/lysine-torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 5 completed in 67.25 seconds =====\n",
      "\n",
      "--- Cross-validation Summary for Hybrid GINE+ProtT5 (Edge Feats: True) (Avg +/- Std Dev on Val Folds) ---\n",
      "  Avg Val loss           : 0.8500  0.0380\n",
      "  Avg Val accuracy       : 0.7069  0.0044\n",
      "  Avg Val balanced_acc   : 0.7084  0.0049\n",
      "  Avg Val mcc            : 0.4190  0.0119\n",
      "  Avg Val sensitivity    : 0.6675  0.0399\n",
      "  Avg Val specificity    : 0.7494  0.0444\n",
      "\n",
      "--- Final Test Set Performance for Hybrid GINE+ProtT5 (Edge Feats: True) (Ensemble: Majority Vote) ---\n",
      "Ensemble Test Loss: 0.8500\n",
      "Ensemble Test Accuracy: 0.7296\n",
      "Ensemble Test Balanced Acc: 0.7162\n",
      "Ensemble Test MCC: 0.2656\n",
      "Ensemble Test Sensitivity: 0.7000\n",
      "Ensemble Test Specificity: 0.7325\n",
      "Ensemble Test Confusion Matrix:\n",
      "  [[TN=1829  FP=668  ]\n",
      "   [FN=72    TP=168  ]]\n",
      "\n",
      "--- Evaluation for Hybrid GINE+ProtT5 (Edge Feats: True) completed in 502.88 seconds ---\n",
      "\n",
      "\n",
      "========================= Overall Run Summary =========================\n",
      "Configuration        | AvgVal BAcc  | AvgVal MCC   | Test BAcc    | Test MCC    \n",
      "---------------------------------------------------------------------------\n",
      "GATv2_EF             | 0.7068       | 0.4183       | 0.7007       | 0.2508      \n",
      "GATv2_noEF           | 0.7112       | 0.4223       | 0.7169       | 0.2594      \n",
      "GCN_noEF             | 0.7171       | 0.4342       | 0.7165       | 0.2605      \n",
      "GINE_EF              | 0.7084       | 0.4190       | 0.7162       | 0.2656      \n",
      "PNA_noEF             | 0.7057       | 0.4142       | 0.7128       | 0.2629      \n",
      "\n",
      "===========================================================================\n",
      "Total execution finished in 47.93 minutes.\n",
      "===== Evaluation Complete =====\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    overall_start_time = time.time()\n",
    "\n",
    "    # --- Configuration ---\n",
    "    DISTANCE_THRESHOLD = 8.0 # Angstrom cutoff for graph edges\n",
    "\n",
    "    # Default hyperparameters (can be overridden in specific configs)\n",
    "    default_hypers = {\n",
    "        'hidden_dim': 128,\n",
    "        'layers': 3,          # Number of GNN layers\n",
    "        'heads': 4,           # Number of heads for GATv2\n",
    "        'gnn_dropout': 0.4,   # Dropout within GNN layers\n",
    "        'pt5_mlp_dropout': 0.4, # Dropout within ProtT5 MLP\n",
    "        'classifier_dropout': 0.5, # Dropout in final classifier\n",
    "        'lr': 0.001,          # Learning rate\n",
    "        'weight_decay': 0.01, # Weight decay for AdamW\n",
    "        'epochs': 50,         # Max epochs per fold\n",
    "        'patience': 10,         # Early stopping patience\n",
    "        'batch_size': 32,       # Batch size for training/evaluation\n",
    "        'use_ss_node_feature': True # Include SS one-hot in node features\n",
    "    }\n",
    "\n",
    "    # Define model configurations to test\n",
    "    model_configs = [\n",
    "        # --- Models NOT using Edge Features ---\n",
    "        {\n",
    "            'config_label': 'GCN_noEF', # Descriptive label\n",
    "            'gnn_type': 'gcn',\n",
    "            'use_edge_features': False,\n",
    "            **default_hypers\n",
    "        },\n",
    "        {\n",
    "            'config_label': 'PNA_noEF',\n",
    "            'gnn_type': 'pna',\n",
    "            'use_edge_features': False,\n",
    "            **default_hypers\n",
    "        },\n",
    "        {\n",
    "            'config_label': 'GATv2_noEF',\n",
    "            'gnn_type': 'gatv2',\n",
    "            'use_edge_features': False, # Explicitly no edge features\n",
    "            **default_hypers # Includes default heads=4\n",
    "        },\n",
    "        # --- Models USING Edge Features ---\n",
    "        {\n",
    "            'config_label': 'GATv2_EF',\n",
    "            'gnn_type': 'gatv2',\n",
    "            'use_edge_features': True, # Will use edge_attr if created\n",
    "            **default_hypers # Includes default heads=4\n",
    "        },\n",
    "        {\n",
    "            'config_label': 'GINE_EF',\n",
    "            'gnn_type': 'gine',\n",
    "            'use_edge_features': True, # GINE requires edge features\n",
    "            **default_hypers\n",
    "        },\n",
    "        # --- Add more specific hyperparameter variations below if needed ---\n",
    "        # e.g., {'config_label': 'GCN_L4_H256', 'gnn_type': 'gcn', 'use_edge_features': False, **default_hypers, 'layers': 4, 'hidden_dim': 256},\n",
    "    ]\n",
    "\n",
    "    # --- File Paths (!!! IMPORTANT: Update these paths !!!) ---\n",
    "    # Adjust relative paths based on where we run the script\n",
    "    base_data_path = \"../../data/\"\n",
    "\n",
    "    try:\n",
    "        train_csv_path = os.path.join(base_data_path, \"train/structure/processed_features_train.csv\")\n",
    "        test_csv_path = os.path.join(base_data_path, \"test/structure/processed_features_test.csv\")\n",
    "        train_pos_prot_t5_path = os.path.join(base_data_path, 'train/PLM/train_positive_ProtT5-XL-UniRef50.csv')\n",
    "        train_neg_prot_t5_path = os.path.join(base_data_path, 'train/PLM/train_negative_ProtT5-XL-UniRef50.csv')\n",
    "        test_pos_prot_t5_path = os.path.join(base_data_path, 'test/PLM/test_positive_ProtT5-XL-UniRef50.csv')\n",
    "        test_neg_prot_t5_path = os.path.join(base_data_path, 'test/PLM/test_negative_ProtT5-XL-UniRef50.csv')\n",
    "\n",
    "        print(\"\\n--- File Paths Used ---\")\n",
    "        print(f\"Train CSV: {os.path.abspath(train_csv_path)}\")\n",
    "        print(f\"Test CSV: {os.path.abspath(test_csv_path)}\")\n",
    "        print(f\"Train ProtT5 (+): {os.path.abspath(train_pos_prot_t5_path)}\")\n",
    "        # ... print other paths if desired ...\n",
    "        print(\"-----------------------\")\n",
    "\n",
    "        # --- Data Loading ---\n",
    "        print(\"\\nLoading main feature CSV data...\")\n",
    "        if not os.path.exists(train_csv_path): raise FileNotFoundError(f\"Train CSV: {train_csv_path}\")\n",
    "        if not os.path.exists(test_csv_path): raise FileNotFoundError(f\"Test CSV: {test_csv_path}\")\n",
    "        train_df_orig = pd.read_csv(train_csv_path)\n",
    "        test_df_orig = pd.read_csv(test_csv_path)\n",
    "        print(f\"Loaded {len(train_df_orig)} training, {len(test_df_orig)} test samples from CSV.\")\n",
    "        if train_df_orig.empty: raise ValueError(\"Training DataFrame empty.\")\n",
    "\n",
    "        # --- Load ProtT5 Data ---\n",
    "        train_pos_dict, train_neg_dict = load_prot_t5_data(train_pos_prot_t5_path, train_neg_prot_t5_path)\n",
    "        test_pos_dict, test_neg_dict = load_prot_t5_data(test_pos_prot_t5_path, test_neg_prot_t5_path)\n",
    "\n",
    "        if train_pos_dict is None or train_neg_dict is None: raise RuntimeError(\"Failed to load Training ProtT5 embeddings.\")\n",
    "        # Handle potentially missing test embeddings gracefully\n",
    "        can_test = not test_df_orig.empty and test_pos_dict is not None and test_neg_dict is not None\n",
    "\n",
    "        # --- Align Data ---\n",
    "        print(\"\\nAligning training data...\")\n",
    "        X_train_prot_t5, train_df_aligned = prepare_aligned_data(train_df_orig, train_pos_dict, train_neg_dict)\n",
    "\n",
    "        if train_df_aligned.empty or X_train_prot_t5.size == 0: raise ValueError(\"Training data alignment resulted in empty data.\")\n",
    "\n",
    "        X_test_prot_t5, test_df_aligned = None, pd.DataFrame(columns=test_df_orig.columns) # Defaults\n",
    "        if can_test:\n",
    "            print(\"\\nAligning test data...\")\n",
    "            X_test_prot_t5, test_df_aligned = prepare_aligned_data(test_df_orig, test_pos_dict, test_neg_dict)\n",
    "            if test_df_aligned.empty or X_test_prot_t5.size == 0:\n",
    "                print(\"Warning: Test data alignment resulted in empty data. Test evaluation skipped.\")\n",
    "                can_test = False\n",
    "        else: print(\"\\nTest data alignment skipped.\")\n",
    "\n",
    "        print(f\"\\n--- Aligned Data Shapes ---\")\n",
    "        print(f\"Train DF: {train_df_aligned.shape}, Train ProtT5: {X_train_prot_t5.shape}\")\n",
    "        if can_test: print(f\"Test DF : {test_df_aligned.shape}, Test ProtT5 : {X_test_prot_t5.shape}\")\n",
    "        else: print(\"Test Data: Not available or alignment failed.\")\n",
    "        print(\"--------------------------\\n\")\n",
    "\n",
    "    # --- Error handling for data loading/alignment ---\n",
    "    except FileNotFoundError as e: print(f\"\\nFATAL ERROR: Data file not found.\\n {e}\\nPlease check paths.\"); exit()\n",
    "    except ValueError as e: print(f\"\\nFATAL ERROR: Problem with data content or alignment.\\n {e}\"); exit()\n",
    "    except RuntimeError as e: print(f\"\\nFATAL ERROR: Runtime issue during data loading.\\n {e}\"); exit()\n",
    "    except Exception as e: print(f\"FATAL ERROR during data setup: {e}\"); traceback.print_exc(); exit()\n",
    "\n",
    "\n",
    "    # --- Store Results ---\n",
    "    all_results_summary = {} # Store key metrics for final comparison\n",
    "\n",
    "    # --- Loop through configurations and run training/evaluation ---\n",
    "    for config in model_configs:\n",
    "        config_label = config.get('config_label', f\"{config['gnn_type']}_{'EF' if config.get('use_edge_features', False) else 'noEF'}\")\n",
    "\n",
    "        # --- Run evaluation ---\n",
    "        try:\n",
    "            # Call the main training/CV function with ALIGNED data\n",
    "            avg_cv_metrics, final_test_metrics = train_and_evaluate_hybrid_model(\n",
    "                train_df_aligned=train_df_aligned,\n",
    "                train_prot_t5=X_train_prot_t5,\n",
    "                test_df_aligned=test_df_aligned,\n",
    "                test_prot_t5=X_test_prot_t5,\n",
    "                model_config=config, # Pass the specific config for this run\n",
    "                distance_threshold=DISTANCE_THRESHOLD,\n",
    "                n_splits=5 # Fixed 5 folds\n",
    "            )\n",
    "            # Store key results for summary\n",
    "            all_results_summary[config_label] = {\n",
    "                'avg_val_bacc': avg_cv_metrics.get('balanced_acc', float('nan')) if avg_cv_metrics else float('nan'),\n",
    "                'avg_val_mcc': avg_cv_metrics.get('mcc', float('nan')) if avg_cv_metrics else float('nan'),\n",
    "                'test_bacc': final_test_metrics.get('balanced_acc', float('nan')) if final_test_metrics else float('nan'),\n",
    "                'test_mcc': final_test_metrics.get('mcc', float('nan')) if final_test_metrics else float('nan')\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"\\n--- !!! CRITICAL ERROR during evaluation for {config_label} !!! ---\")\n",
    "            print(f\"Error: {e}\")\n",
    "            traceback.print_exc()\n",
    "            all_results_summary[config_label] = {'error': str(e)} # Log the error\n",
    "        # --- End of loop for one configuration ---\n",
    "\n",
    "\n",
    "    # --- Final Summary ---\n",
    "    print(\"\\n\\n\" + \"=\"*25 + \" Overall Run Summary \" + \"=\"*25)\n",
    "    print(f\"{'Configuration':<20} | {'AvgVal BAcc':<12} | {'AvgVal MCC':<12} | {'Test BAcc':<12} | {'Test MCC':<12}\")\n",
    "    print(\"-\" * 75)\n",
    "    # Sort by label maybe\n",
    "    sorted_labels = sorted(all_results_summary.keys())\n",
    "    for config_label in sorted_labels:\n",
    "        results = all_results_summary[config_label]\n",
    "        if 'error' in results:\n",
    "            print(f\"{config_label:<20} | {'ERROR':<12} | {'ERROR':<12} | {'ERROR':<12} | {'ERROR':<12}\")\n",
    "            print(f\"  Error: {results['error']}\")\n",
    "        else:\n",
    "            val_bacc_str = f\"{results['avg_val_bacc']:.4f}\" if not np.isnan(results['avg_val_bacc']) else \"N/A\"\n",
    "            val_mcc_str = f\"{results['avg_val_mcc']:.4f}\" if not np.isnan(results['avg_val_mcc']) else \"N/A\"\n",
    "            test_bacc_str = f\"{results['test_bacc']:.4f}\" if not np.isnan(results['test_bacc']) else \"N/A\"\n",
    "            test_mcc_str = f\"{results['test_mcc']:.4f}\" if not np.isnan(results['test_mcc']) else \"N/A\"\n",
    "            print(f\"{config_label:<20} | {val_bacc_str:<12} | {val_mcc_str:<12} | {test_bacc_str:<12} | {test_mcc_str:<12}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*75)\n",
    "    overall_end_time = time.time()\n",
    "    print(f\"Total execution finished in {(overall_end_time - overall_start_time)/60:.2f} minutes.\")\n",
    "    print(\"===== Evaluation Complete =====\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lysine-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
