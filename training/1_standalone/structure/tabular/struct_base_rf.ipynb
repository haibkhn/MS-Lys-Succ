{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 16:57:03.649442: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744131423.667578  992553 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744131423.673098  992553 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-08 16:57:03.692136: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "tf.keras.utils.set_random_seed(SEED)  # This sets all random seeds in keras\n",
    "tf.config.experimental.enable_op_determinism()  # For complete reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_structure_data(df):\n",
    "    \"\"\"Structure data preparation without contacts\"\"\"\n",
    "    features_list = []\n",
    "    middle_pos = 16  \n",
    "    \n",
    "    # Normalize angles to their circular nature\n",
    "    def normalize_angles(angle_array, pos):\n",
    "        angles = np.array([arr[pos] for arr in angle_array])\n",
    "        angle_rad = np.pi * angles / 180.0\n",
    "        return np.stack([np.sin(angle_rad), np.cos(angle_rad)], axis=-1)\n",
    "    \n",
    "    # 1. Process angles\n",
    "    angles = ['phi', 'psi', 'omega']\n",
    "    for angle in angles:\n",
    "        angle_arrays = np.array([np.array(eval(x)) for x in df[angle]])\n",
    "        angle_features = normalize_angles(angle_arrays, middle_pos)\n",
    "        features_list.append(angle_features)\n",
    "        print(f\"{angle} features shape: {angle_features.shape}\")\n",
    "    \n",
    "    # 2. Process SASA\n",
    "    sasa_arrays = np.array([np.array(eval(x)) for x in df['sasa']])\n",
    "    scaler = RobustScaler()\n",
    "    sasa_features = []\n",
    "    for pos in [middle_pos-1, middle_pos, middle_pos+1]:\n",
    "        sasa_pos = np.array([arr[pos] for arr in sasa_arrays]).reshape(-1, 1)\n",
    "        sasa_scaled = scaler.fit_transform(sasa_pos)\n",
    "        sasa_features.append(sasa_scaled)\n",
    "    sasa_features = np.concatenate(sasa_features, axis=1)\n",
    "    features_list.append(sasa_features)\n",
    "    print(f\"SASA features shape: {sasa_features.shape}\")\n",
    "    \n",
    "    # 3. Process chi angles\n",
    "    chi_angles = ['chi1', 'chi2', 'chi3', 'chi4']\n",
    "    for chi in chi_angles:\n",
    "        chi_arrays = np.array([np.array(eval(x)) for x in df[chi]])\n",
    "        chi_features = normalize_angles(chi_arrays, middle_pos)\n",
    "        features_list.append(chi_features)\n",
    "        print(f\"{chi} features shape: {chi_features.shape}\")\n",
    "    \n",
    "    # 4. Process SS (optional)\n",
    "    ss_arrays = np.array([list(seq) for seq in df['ss']])\n",
    "    ss_center = ss_arrays[:, middle_pos]\n",
    "    ss_encoded = np.zeros((len(ss_arrays), 3))\n",
    "    ss_map = {'H': 0, 'E': 1, 'L': 2}\n",
    "    for i, ss in enumerate(ss_center):\n",
    "        ss_encoded[i, ss_map[ss]] = 1\n",
    "    features_list.append(ss_encoded)\n",
    "    print(f\"SS features shape: {ss_encoded.shape}\")\n",
    "    \n",
    "    # 5. Process plDDT\n",
    "    plddt_arrays = np.array([np.array(eval(x)) for x in df['plDDT']])\n",
    "    plddt_center = np.array([arr[middle_pos] for arr in plddt_arrays]).reshape(-1, 1)\n",
    "    scaler = RobustScaler()\n",
    "    plddt_scaled = scaler.fit_transform(plddt_center)\n",
    "    features_list.append(plddt_scaled)\n",
    "    print(f\"plDDT features shape: {plddt_scaled.shape}\")\n",
    "    \n",
    "    # Combine all features\n",
    "    features = np.concatenate(features_list, axis=1)\n",
    "    print(f\"\\nFinal combined features shape: {features.shape}\")\n",
    "    print(\"Feature list lengths:\", [f.shape[1] for f in features_list])\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_structure_model(input_dim):\n",
    "    \"\"\"Create a standalone model for structural features\n",
    "    \n",
    "    Args:\n",
    "        input_dim: The dimensionality of the structural features\n",
    "        \n",
    "    Returns:\n",
    "        A compiled Keras model\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(input_dim,)),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Print comprehensive evaluation metrics\n",
    "    \n",
    "    Parameters:\n",
    "    y_true: array-like of true labels\n",
    "    y_pred: array-like of predicted labels\n",
    "    \"\"\"\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    sensitivity = cm[1][1] / (cm[1][1] + cm[1][0])  # True Positive Rate\n",
    "    specificity = cm[0][0] / (cm[0][0] + cm[0][1])  # True Negative Rate\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
    "    print(f\"MCC: {mcc:.4f}\")\n",
    "    print(f\"Sensitivity: {sensitivity:.4f}\")\n",
    "    print(f\"Specificity: {specificity:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def train_and_evaluate_seq_only_rf():\n",
    "    \"\"\"Train and evaluate structure-based model using Random Forest\"\"\"\n",
    "    print(\"Loading structural data...\")\n",
    "    \n",
    "    # Load data\n",
    "    train_df = pd.read_csv(\"../../../../data/train/structure/processed_features_train.csv\")\n",
    "    test_df = pd.read_csv(\"../../../../data/test/structure/processed_features_test.csv\")\n",
    "    \n",
    "    # Extract labels\n",
    "    y_train = train_df['label'].values\n",
    "    y_test = test_df['label'].values\n",
    "    \n",
    "    # Prepare feature data\n",
    "    X_train = prepare_structure_data(train_df)\n",
    "    X_test = prepare_structure_data(test_df)\n",
    "    \n",
    "    # Shuffle training data\n",
    "    shuffle_idx = np.random.RandomState(42).permutation(len(y_train))\n",
    "    X_train = X_train[shuffle_idx]\n",
    "    y_train = y_train[shuffle_idx]\n",
    "    \n",
    "    print(f\"Training data shape: {X_train.shape}\")\n",
    "    print(f\"Testing data shape: {X_test.shape}\")\n",
    "    \n",
    "    # Cross-validation setup\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    metrics = {'acc': [], 'balanced_acc': [], 'mcc': [], 'sn': [], 'sp': []}\n",
    "    test_predictions = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train, y_train), 1):\n",
    "        print(f\"\\nFold {fold}/5\")\n",
    "        \n",
    "        # Create Random Forest model\n",
    "        \n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            min_samples_split=5,\n",
    "            min_samples_leaf=2,\n",
    "            class_weight='balanced',\n",
    "            random_state=42,\n",
    "            n_jobs=-1  # Use all processors\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_train[train_idx], y_train[train_idx])\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_pred = model.predict_proba(X_train[val_idx])[:, 1]\n",
    "        val_pred_binary = (val_pred > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        cm = confusion_matrix(y_train[val_idx], val_pred_binary)\n",
    "        metrics['acc'].append(accuracy_score(y_train[val_idx], val_pred_binary))\n",
    "        metrics['balanced_acc'].append(balanced_accuracy_score(y_train[val_idx], val_pred_binary))\n",
    "        metrics['mcc'].append(matthews_corrcoef(y_train[val_idx], val_pred_binary))\n",
    "        metrics['sn'].append(cm[1][1]/(cm[1][1]+cm[1][0]))\n",
    "        metrics['sp'].append(cm[0][0]/(cm[0][0]+cm[0][1]))\n",
    "        \n",
    "        # Predict on test set\n",
    "        test_pred = model.predict_proba(X_test)[:, 1]\n",
    "        test_predictions.append(test_pred)\n",
    "        \n",
    "        print(f\"\\nFold {fold} Results:\")\n",
    "        print(f\"Accuracy: {metrics['acc'][-1]:.4f}\")\n",
    "        print(f\"Balanced Accuracy: {metrics['balanced_acc'][-1]:.4f}\")\n",
    "        print(f\"MCC: {metrics['mcc'][-1]:.4f}\")\n",
    "        print(f\"Sensitivity: {metrics['sn'][-1]:.4f}\")\n",
    "        print(f\"Specificity: {metrics['sp'][-1]:.4f}\")\n",
    "        \n",
    "        # Feature importance for this fold\n",
    "        feature_importance = model.feature_importances_\n",
    "        print(f\"\\nTop 5 important features for fold {fold}:\")\n",
    "        top_indices = np.argsort(feature_importance)[-5:]\n",
    "        for i in top_indices[::-1]:\n",
    "            print(f\"Feature {i}: {feature_importance[i]:.4f}\")\n",
    "    \n",
    "    # Print average cross-validation results\n",
    "    print(\"\\nAverage Cross-validation Results:\")\n",
    "    for metric in metrics:\n",
    "        print(f\"{metric.upper()}: {np.mean(metrics[metric]):.4f} ± {np.std(metrics[metric]):.4f}\")\n",
    "    \n",
    "    # Ensemble predictions on test set\n",
    "    test_pred_avg = np.mean(test_predictions, axis=0)\n",
    "    test_pred_binary = (test_pred_avg > 0.5).astype(int)\n",
    "    \n",
    "    # Calculate final test metrics\n",
    "    cm_test = confusion_matrix(y_test, test_pred_binary)\n",
    "    \n",
    "    print(\"\\nFinal Test Set Results:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, test_pred_binary):.4f}\")\n",
    "    print(f\"Balanced Accuracy: {balanced_accuracy_score(y_test, test_pred_binary):.4f}\")\n",
    "    print(f\"MCC: {matthews_corrcoef(y_test, test_pred_binary):.4f}\")\n",
    "    print(f\"Sensitivity: {cm_test[1][1]/(cm_test[1][1]+cm_test[1][0]):.4f}\")\n",
    "    print(f\"Specificity: {cm_test[0][0]/(cm_test[0][0]+cm_test[0][1]):.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm_test)\n",
    "    \n",
    "    return model, test_pred_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading structural data...\n",
      "phi features shape: (8853, 2)\n",
      "psi features shape: (8853, 2)\n",
      "omega features shape: (8853, 2)\n",
      "SASA features shape: (8853, 3)\n",
      "chi1 features shape: (8853, 2)\n",
      "chi2 features shape: (8853, 2)\n",
      "chi3 features shape: (8853, 2)\n",
      "chi4 features shape: (8853, 2)\n",
      "SS features shape: (8853, 3)\n",
      "plDDT features shape: (8853, 1)\n",
      "\n",
      "Final combined features shape: (8853, 21)\n",
      "Feature list lengths: [2, 2, 2, 3, 2, 2, 2, 2, 3, 1]\n",
      "phi features shape: (2737, 2)\n",
      "psi features shape: (2737, 2)\n",
      "omega features shape: (2737, 2)\n",
      "SASA features shape: (2737, 3)\n",
      "chi1 features shape: (2737, 2)\n",
      "chi2 features shape: (2737, 2)\n",
      "chi3 features shape: (2737, 2)\n",
      "chi4 features shape: (2737, 2)\n",
      "SS features shape: (2737, 3)\n",
      "plDDT features shape: (2737, 1)\n",
      "\n",
      "Final combined features shape: (2737, 21)\n",
      "Feature list lengths: [2, 2, 2, 3, 2, 2, 2, 2, 3, 1]\n",
      "Training data shape: (8853, 21)\n",
      "Testing data shape: (2737, 21)\n",
      "\n",
      "Fold 1/5\n",
      "\n",
      "Fold 1 Results:\n",
      "Accuracy: 0.6302\n",
      "Balanced Accuracy: 0.6277\n",
      "MCC: 0.2577\n",
      "Sensitivity: 0.6931\n",
      "Specificity: 0.5622\n",
      "\n",
      "Top 5 important features for fold 1:\n",
      "Feature 20: 0.1443\n",
      "Feature 6: 0.0951\n",
      "Feature 8: 0.0715\n",
      "Feature 7: 0.0644\n",
      "Feature 5: 0.0519\n",
      "\n",
      "Fold 2/5\n",
      "\n",
      "Fold 2 Results:\n",
      "Accuracy: 0.6245\n",
      "Balanced Accuracy: 0.6224\n",
      "MCC: 0.2464\n",
      "Sensitivity: 0.6779\n",
      "Specificity: 0.5669\n",
      "\n",
      "Top 5 important features for fold 2:\n",
      "Feature 20: 0.1322\n",
      "Feature 6: 0.1016\n",
      "Feature 8: 0.0703\n",
      "Feature 7: 0.0695\n",
      "Feature 5: 0.0517\n",
      "\n",
      "Fold 3/5\n",
      "\n",
      "Fold 3 Results:\n",
      "Accuracy: 0.6313\n",
      "Balanced Accuracy: 0.6299\n",
      "MCC: 0.2606\n",
      "Sensitivity: 0.6678\n",
      "Specificity: 0.5920\n",
      "\n",
      "Top 5 important features for fold 3:\n",
      "Feature 20: 0.1378\n",
      "Feature 6: 0.1014\n",
      "Feature 8: 0.0691\n",
      "Feature 7: 0.0666\n",
      "Feature 5: 0.0519\n",
      "\n",
      "Fold 4/5\n",
      "\n",
      "Fold 4 Results:\n",
      "Accuracy: 0.6124\n",
      "Balanced Accuracy: 0.6104\n",
      "MCC: 0.2222\n",
      "Sensitivity: 0.6656\n",
      "Specificity: 0.5552\n",
      "\n",
      "Top 5 important features for fold 4:\n",
      "Feature 20: 0.1435\n",
      "Feature 6: 0.0966\n",
      "Feature 8: 0.0690\n",
      "Feature 7: 0.0656\n",
      "Feature 5: 0.0534\n",
      "\n",
      "Fold 5/5\n",
      "\n",
      "Fold 5 Results:\n",
      "Accuracy: 0.6260\n",
      "Balanced Accuracy: 0.6237\n",
      "MCC: 0.2494\n",
      "Sensitivity: 0.6841\n",
      "Specificity: 0.5634\n",
      "\n",
      "Top 5 important features for fold 5:\n",
      "Feature 20: 0.1300\n",
      "Feature 6: 0.1048\n",
      "Feature 8: 0.0716\n",
      "Feature 7: 0.0685\n",
      "Feature 5: 0.0530\n",
      "\n",
      "Average Cross-validation Results:\n",
      "ACC: 0.6249 ± 0.0067\n",
      "BALANCED_ACC: 0.6228 ± 0.0068\n",
      "MCC: 0.2473 ± 0.0136\n",
      "SN: 0.6777 ± 0.0103\n",
      "SP: 0.5679 ± 0.0126\n",
      "\n",
      "Final Test Set Results:\n",
      "Accuracy: 0.4867\n",
      "Balanced Accuracy: 0.5850\n",
      "MCC: 0.0966\n",
      "Sensitivity: 0.7042\n",
      "Specificity: 0.4658\n",
      "Confusion Matrix:\n",
      "[[1163 1334]\n",
      " [  71  169]]\n"
     ]
    }
   ],
   "source": [
    "model, test_probs = train_and_evaluate_seq_only_rf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetune-dephos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
